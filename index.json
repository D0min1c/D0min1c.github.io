[{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.toml\n``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nBúsqueda de archivos adicionales Para buscar campos adicionales definidos en el front matter, debes añadirlo en 2 lugares.\nEditar layouts/_default/index.JSON Esto expone los valores en /index.json: por ejemplo, para agregar categories ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEditar las opciones de fuse.js para buscar static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"Este archivo existe únicamente para responder a la URL /search con la plantilla de diseño search relacionada.\nNo se muestra ningún contenido aquí, todo el contenido se basa en la plantilla layouts/page/search.html\nEstablecer una prioridad muy baja en el mapa del sitio le dirá a los motores de búsqueda que éste no es un contenido importante.\nEsta implementación utiliza Fusejs, jquery y mark.js\nConfiguración inicial La búsqueda depende del tipo de contenido de salida adicional de JSON en config.","tags":null,"title":"Resultados de Búsqueda"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"June 8, 2010","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"অনুসন্ধানের ফলাফল"},{"categories":null,"contents":"AWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\n배경 AWS를 시작하시는 분들을 위해 간단하게 AMI에 대해 정리해보았습니다.\nAMI 개념 (Amazon Machine Image) (AKA. AMI) Amazon 머신 이미지(AMI)는 인스턴스를 시작하는 데 필요한 정보를 제공합니다. 인스턴스를 시작할 때 AMI를 지정해야 합니다. 제공되는 템플릿 AMI를 사용하여 커스텀한 서버나 애플리케이션 인스턴스 자체를 AMI로 풀백업하여 보관하는것도 가능합니다.\nAMI 사용사례 모든 인스턴스의 시작은 AMI에서부터 시작합니다. 또한 AMI의 경우 EBS 스냅샷을 포함하여 풀백업 (OS셋팅까지도)되기에 백업해두는 용도로 많이 사용하게 됩니다. AMI로 표준 이미지를 생성해두고 해당 이미지를 통해 여러 서버를 복제하거나 Autoscaling과 연동하여 사용할 수 있습니다.\n혹은 AMI를 리전 간 복제하여 다른 리전에, 다른계정에 공유하여 다른 계정 내 VPC에도 이미지를 불러 사용할 수 있습니다.\nAMI 요금 인스턴스 스토어 지원 AMI의 경우 AMI 스토리지 및 인스턴스 사용 및 Amazon S3에 AMI 저장에 대해 요금이 부과됩니다. Amazon EBS 기반 AMI를 사용하는 경우 인스턴스 사용, EBS 볼륨 스토리지 및 사용, AMI를 EBS 스냅샷으로 저장에 대해 요금이 부과됩니다.\n결론 결론적으로 AMI는 인스턴스의 풀백업 이미지입니다. 이를 통해 서버 규격에 대한 표준을 정하여두고 버저닝하여 관리하는 것이 용이합니다. 또한 만든 AMI를 AWS Marketplace로 판매할 수 있기도합니다.\n","date":"July 5, 2021","hero":"/posts/aws_beginners/ami/images/host_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/aws_beginners/ami/","summary":"\u003cp\u003eAWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\u003c/p\u003e","tags":null,"title":"비기너라면 알아두어야 할 AMI"},{"categories":null,"contents":"AWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\n배경 AWS를 시작하시는 분들을 위해 간단하게 EC2 라는 서비스에 대해 정리해보았습니다. 가상화나 상세 기술내용은 도려낸 핵심적인 내용만 담아봤습니다.\nEC2 개념 (Elastic Compute Cloud) (AKA. 인스턴스) AWS에서 운영하는 데이터 센터 내 여러 Host Server 위에 Hypervisor라 불리우는 소프트웨어를 통해 하드웨어의 리소스에서 가상머신의 리소스를 분리하고 프로비저닝하여 사용자에게 제공합니다.\n현재 AWS에서 EC2 가상화 종류에 따라 최신세대 인스턴스 (Nitro Type이라 불리는 KVM 기반 Hypervisor), 이전세대 인스턴스 (Xen 기반 Hypervisor)로 나뉩니다.\n이러한 VM들을 AWS에서는 EC2라는 이름으로 사용자에게 제공합니다.\nEC2 계산 (Elastic Compute Cloud) (AKA. 인스턴스) 기본적으로 클라우드 컴퓨팅은 사용한 만큼 비용을 지불하는 방식이 적용됩니다. 마치 PC방처럼요.\n그런데, 제공함에 있어 비용적으로 선택할 수 있는 옵션이 4가지 있습니다.\n  On-demand : 사용한 만큼 비용 지불 (초 당 비용으로 지불되며 최소 60초(1분)가 적용됩니다.)\n  Spot : 낚시와 비슷한 개념입니다. AWS에서는 남는 EC2 유휴자원들을 시장에 싼값에 내놓습니다. 고정된 가격이 아니기에, 사용자는 인스턴스별 시간당 지불하려는 최고 가격을 설정해두어 지불하려는 최고 가격이 스팟 가격을 초과하고 사용 가능한 용량이 있는 경우 스팟 인스턴스가 시작됩니다. 이말인 즉슨 지불하려는 가격보다 인스턴스가 비싸지면 인스턴스가 종료될 수도 있다는 말입니다. 예전에는 볼륨과 함께 인스턴스가 증발했지만, 이젠 EBS를 따로 보호할 수 있는 옵션도 생겼기에, 나쁘지 않은 조건이라고 생각합니다.\n  다만 실 서비스에서는 온디멘드 인스턴스나 RI같은 고정적인 인스턴스와 함께 사용하는 것이 일반적입니다.\n RI : Reserved Instance의 약자로 컴퓨팅을 미리 예약해두고 사용하는 것입니다. 1년 2년 약정형식으로 동일 스펙의 On-demand 인스턴스에 비해 약 75% 비용 절감 효과를 얻을 수 있습니다. 일반적으로 같은 인스턴스 패밀리 내에서는 사이즈를 변경할 수 있지만, 다른 인스턴스 패밀리로 변경하고자한다면 Convertible RI로 구매하셔야합니다. (호텔 장기투숙과 비슷)\n  Saving Plan : RI와 비슷한 개념입니다만, RI는 연간 컴퓨팅을 쓰던 안쓰던 비용이 청구되는 방식이지만, Saving Plan은 시간 당 비용으로 계약하기에 실제 사용량에 대해서 청구됩니다.(m4.xlarge인스턴스를 시간당 10달러로 6개월 계약 / PC방 후불제와 비슷)\n  단순 컴퓨팅 비용에서만 계산하는 방식이였습니다. 이외에도 서버를 운영하기 위해서는 Network Traffic 비용, EBS 볼륨비용 등 추가적인 요소들이 존재합니다.\nEC2를 구성하는 요소들 EC2를 생성하려했더니, 선택해야할 옵션이 너무 많아보입니다. 간단하게 설명해드리겠습니다.\n  AMI(Amazon Machine Image) : AMI는 인스턴스를 시작하는 데 필요한 소프트웨어 구성(운영 체제, 애플리케이션 서버, 애플리케이션)이 포함된 템플릿입니다. VM에 설치될 OS와 내부 패키지 구성까지 포함되어있는 템플릿이라고 보시면됩니다. 그러니까.. Window CD같은..\n  인스턴스 타입 : 위에서 언급된 인스턴스 패밀리의 개념입니다. t시리즈, m시리즈, c시리즈 처럼 인스턴스는 성능과 특징에 따라 이니셜링되어 서비스됩니다. 각 인스턴스 패밀리 별 특장점은 AWS Docs에서 자세히 설명되어있기에 따로 다루진 않겠습니다.\n  인스턴스 세부 정보 : 생성할 인스턴스의 갯수, 네트워크 구성(VPC,subnet,ENI)등을 설정합니다. 각각의 항목들이 복잡하지만 중요 구성요소는 네트워크 설정입니다. VPC와 서브넷에 대해서는 AWS Networking 포스팅을 참고하시면 좋습니다.\n  스토리지 추가 : 인스턴스에 디스크를 추가합니다. HDD, SSD 같은 유형을 지원합니다. 이외에도 인스턴스스토어 라는 개념이 존재합니다. 인스턴스의 루트 디바이스에는 인스턴스 부팅에 사용되는 이미지가 포함되어 있습니다.\n  보안 그룹 : 보안 그룹은 인스턴스에 대한 트래픽을 제어하는 방화벽 규칙 세트입니다. 이 페이지에서는 특정 트래픽을 인스턴스에 도달하도록 허용할 규칙을 추가할 수 있습니다. 예를 들면 웹 서버를 설정하여 인터넷 트래픽을 인스턴스에 도달하도록 허용하려는 경우 HTTP 및 HTTPS 트래픽에 대한 무제한 액세스를 허용하는 규칙을 추가합니다.\n  Key-pair 발급 : 기존에 사용하던 키페어가 없으시면 새로운 키페어를 생성하시면 됩니다. 실제 생성되는 VM 내 RSA공개키를 저장해두고 다운로드 받은 개인키를 ssh 접근시 사용하여 VM 내 접속합니다.\n  위 6가지 구성요소를 통해 진행하시면 여러분은 AWS에서 1대의 인스턴스를 제공받고 접근까지 가능하게 되었습니다.\n프리티어 마지막으로 AWS에서는 신규 가입 고객에게 가입한 날로부터 12개월, 혹은 상시로 무료 제공하는 일부 서비스가 있습니다. 이를 \u0026ldquo;프리티어\u0026quot;라고 부르기는 합니다만, Free라고해서 방심하시면 요금폭탄을 맞기 딱 좋기에 서비스를 생성하기 전 요금을 꼭 확인해보고 생성하시길 바랍니다.\n결론 AWS EC2에 대해 간단하게 살펴봤습니다. 각 요소들에 대해 상세한 내용은 이어지는 포스팅을 참고해주시길 바라겠습니다.\n","date":"July 5, 2021","hero":"/posts/aws_beginners/ec2/images/host_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/aws_beginners/ec2/","summary":"\u003cp\u003eAWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\u003c/p\u003e","tags":null,"title":"비기너라면 알아두어야 할 EC2"},{"categories":null,"contents":"AWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\n배경 AWS를 시작하시는 분들을 위해 간단하게 NACL과 SG에 대해 설명합니다.\nNACL 개념 (Network access control list) VPC와 함께 기본적으로 제공되는 NACL은 VPC 내 서브넷 내부와 외부의 트래픽을 제어하기 위한 계층입니다. 서브넷은 한번에 한개의 ACL만을 적용받을 수 있습니다만, ACL은 여러 서브넷에 적용할 수 있습니다. 기본 제공되는 NACL의 경우 모든 IN/Out bound 트래픽에 대해 허용하고 있습니다.\nSG 개념 (SecurityGroup) NACL과 다르게 SG는 각 인스턴스의 방화벽 역할을 합니다. 기본적으로 모든 Inbound 트래픽에 대해 ALL deny 상태로, Outbound 트래픽에 대해 ALL allow 상태로 생성됩니다.\nNACL과 SG의 가장 큰 차이는\nStateless인가, Stateful인가 Stateless, Stateful? Stateless 상태 비저장으로 트래픽에 대한 정보를 저장하지 않습니다. 요청과 응답은 트래픽의 상태와 상관없이 각각 inbound 와 outbound 규칙을 따릅니다.\nStateful 상태 저장으로 트래픽에 대한 정보를 저장합니다. 요청과 응답은 Outbound 규칙과 상관없이 Inbound 트래픽을 허용했다면 이에 대한 응답은 허용됩니다.\n예를 들어, NACL을 통해 80 port에 대한 Inbound 허용을 하였다면, 80에 대한 요청을 서버는 받을 수는 있어도 그에 대한 response를 내보낼 순 없습니다. 이 경우 휘발성 포트에 대한 outbound 허용이 되어있어야 통신이 가능합니다.\n허나 SG를 통해 80 port에 대한 Inbound 허용을 하였다면, Outbound 정책이 어찌됐건 들어온 요청에 대한 Response는 언제든 클라이언트에게 송신됩니다.\n결론 NACL, SG에 대해 알아봤습니다. 두 정책 모두 활용하시는 방법은 권장해드리지 않습니다. SG만으로도 충분하기도하고 NACL까지 세부적으로 설정해뒀는데 나중에 이슈 발생하면 트러블 슈팅이 조금 복잡해질수도 있기 때문이져. 둘 중 하나의 정책만으로도 충분히 기능을 발휘할 수 있습니다.\nAWS의 NACL과 SG에 대해 알아봤습니다.\n","date":"July 5, 2021","hero":"/posts/aws_beginners/security/images/host_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/aws_beginners/security/","summary":"\u003cp\u003eAWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\u003c/p\u003e","tags":null,"title":"비기너라면 알아두어야 할 NACL과 SG"},{"categories":null,"contents":"AWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\n배경 AWS를 시작하시는 분들을 위해 간단하게 AWS 상 서비스되는 Storage 서비스들에 대해 정리해보았습니다.\nAWS Storage 개념 (ElasticBlockService) (AKA. EBS) AWS에서는 여러 스토리지 서비스를 제공합니다. 그중 EC2를 생성함에 있어서 루트 디바이스가 되는 Elastic Block Storage에 대해 알아보고자합니다. 기본적으로 EBS는 EC2 에서 사용하도록 설계된 사용하기 쉬운 원격 블록 스토리지 서비스입니다. EBS 볼륨은 AZ(가용 영역) 내에서 복제되기에 장애로부터 99.999%의 가용성을 보장합니다.\n(사실 99.999% 면, 연간 13초정도는 connection이 끊겨도 AWS에서는 책임이 없단 소립니다.)\nEBS Architecture 큰 그림은 위와 같습니다.\nHost computer 내 1대의 인스턴스가 올라와있고, 인스턴스 내 볼륨은 각 sda1,sdh,sdj,sdb가 마운트 되어있습니다.\n sda1 : Root Device Volume으로 EBS가 마운트되어있습니다. sdh : Data volume으로 EBS가 마운트되어있습니다. sdj : Data volume으로 EBS가 마운트되어있습니다. sdb : Data volume으로 EBS가 아닌 Instance Store가 마운트되어있습니다. (!)  Insatnce Store는 Host Computer에 물리적으로 연결되어있는 디스크입니다. 휘발성 스토리지이기에 버퍼, 캐시, 스크래치 데이터 및 기타 임시 콘텐츠와 같이 자주 변경되는 정보의 임시 스토리지나 로드가 분산된 웹 서버 풀과 같은 여러 인스턴스상에서 복제되는 데이터에 가장 적합합니다.\n   비교 EBS InstanceStore     데이터 보존 영구적 휘발성   분리 가능 불가능   인스턴스 종료 시 유지 가능 유지 불가능    EBS 성능 (ElasticBlockService) (AKA. EBS) EBS 볼륨의 성능을 측정할 때는 관련된 측정 단위와 성능 계산 방법을 이해해야 합니다. IOPS를 기준으로 성능을 좌우합니다. 아래 AWS에서 제공하는 성능비교 링크를 통해 각 유형이 어떤 타입과 성능을 제공하는지 확인할 수 있습니다.\nAWS-EBS 볼륨유형\n프리티어 마지막으로 AWS에서는 신규 가입 고객에게 가입한 날로부터 12개월, 혹은 상시로 무료 제공하는 일부 서비스가 있습니다. 이를 \u0026ldquo;프리티어\u0026quot;라고 부르기는 합니다만, Free라고해서 방심하시면 요금폭탄을 맞기 딱 좋기에 서비스를 생성하기 전 요금을 꼭 확인해보고 생성하시길 바랍니다.\n모니터링 및 백업 EBS는 스냅샷 기능을 통해 백업을 지원합니다. EBS 스냅샷은 특정 시간에 찍은 볼륨의 이미지 사본입니다. 최초의 스냅샷, 즉 이미지 사본은 전체 백업이고, 이후의 스냅샷은 블록-수준의 증분 백업방식을 사용합니다.\nAWS 제공해주는 스냅샷 이해에 도움이되는 이미지입니다. 해석해보자면 이렇습니다.\n 최초 10GB의 볼륨을 스냅샷합니다 (최초 이기에 풀백업 10GB) 이후 10GB의 데이터 중 4GB의 데이터가 변경되었기에 이떄 스냅샷을 생성하면 10GB를 전부 생성하는 것이 아닌, 변경된 4GB에 대한 스냅샷만을 생성합니다. (이전에 생성해둔 스냅샷에서 변경사항이 없는 6GB의 데이터를 유지합니다.) 총 용량은 여전히 10GB입니다. 10GB에서 2GB의 볼륨을 추가하여 총 볼륨량이 12GB가 되었습니다. 마찬가지로 이 2GB에 대해서만 증분 복제합니다.  결론적으로 3의 과정을 거치면서 생긴 스냅샷은 최초 스냅샷 10GB+2번에서 변경된 데이터 4GB+ 3번에서 추가된 2GB =16GB가 스냅샷으로 백업되어 있는 것 입니다.\n그렇기에 중복되는 데이터의 백업을 줄여 총 백업 데이터 량에서 비용 효율적인 백업을 할 수 있습니다. 이 이미지는 S3에서 하나의 객체로 저장되지만, 실제 사용자가 볼수 없는 AWS 관리형 S3에 저장됩니다.\nEBS를 사용함에 있어 주 모니터링 메트릭은 저의 경우 Read/WriteOps와 QueueLength를 가장 먼저 살펴봅니다. 실제 발생하는 IOPS의 양과 처리되지 못하여 Queue에 쌓이는 요청이 늘어날 경우 볼륨의 크기를 키워 IOPS를 늘리거나 타입을 변경하여 해소하곤 했던 기억이 있습니다. (현재는 비용보단 성능에 집중하여 모든 서비스 볼륨은 io2로 사용하고 있습니다.)\n결론 AWS Storage에 대해 살펴보았습니다. 이밖에도 I/O 버스트 크레딧과 IOPS 계산방법 등이 있으나, 여타 다른 블로그에서 잘 설명되어왔기에 비교적 서비스 핵심적인 내용만 메모해두었습니다.\n","date":"July 5, 2021","hero":"/posts/aws_beginners/ebs/images/host_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/aws_beginners/ebs/","summary":"\u003cp\u003eAWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\u003c/p\u003e","tags":null,"title":"비기너라면 알아두어야 할 Storage"},{"categories":null,"contents":"AWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\n배경 AWS를 시작하시는 분들을 위해 간단하게 VPC 서비스에 대해 정리해보았습니다.\nVPC 개념 (Virtual Private Cloud) (AKA. VPC) AWS 내 네트워크 입니다. 사용자가 정의한 가상 네트워크 내 다양한 서비스 가령 EC2등의 서버를 올리는 등, AWS의 네트워크 인프라를 구축할 수 있습니다.\nVPC 구성요소 Virtual Private Cloud(VPC) 사용자의 AWS 계정 전용 가상 네트워크입니다. 논리적으로 분리되어있습니다. AWS 계정을 생성하면 기본적으로 Default VPC를 제공받게 되는데, 이를 활용하셔도되고 직접 VPC를 생성하셔서 사용하셔도 됩니다.\n VPC를 생성하고자 한다면 IPv4 Cidr값을 설정해야합니다. (예시 10.0.0.0/16)   생성 직후 VPC정보 입니다. 항목별 내용은 아래 기재해두겠습니다.  Tenancy 전용 테넌시는 VPC에서 시작된 모든 EC2 인스턴스가 단일 고객 전용 하드웨어에서 실행되도록합니다. 하드웨어를 예약해두고 쓴다라는 개념입니다. 그렇기에 비용이 발생합니다. 기본으로 설정할 경우 해당 리전의 AWS 하드웨어의 어딘가에 리소스들이 생성되는 로직입니다.\n보안에 민감한 서비스의 경우거나, 리소스를 선점하고 사용하려할 때 혹은 라이센스 이슈로 인해 전용호스트가 필요할 경우가 사용하는 옵션입니다.\nSubnet VPC의 대역을 subneting하여 분리한 공간입니다. 보조 Cidr 대역이라고 생각하면 될거같습니다.\nRFC 1918 규격에 맞춰 사설 IP대역을 나눠주는게 좋습니다. 각 서브넷 CIDR 블록에서 첫 4개의 IP 주소와 마지막 IP 주소는 사용자가 사용할 수 없으므로 인스턴스에 할당할 수 없습니다.\n예를 들어 10.0.0.0/24 CIDR 블록의 서브넷에서는 다음 5개 IP 주소가 예약되어 있습니다.\n  10.0.0.0: 네트워크 주소.\n  10.0.0.1: AWS에서 VPC 라우터용으로 예약한 주소.\n  10.0.0.2: AWS에서 예약한 주소 DNS 서버의 IP 주소는 기본 VPC 네트워크 범위에 2를 더한 주소입니다. CIDR 블록이 여러 개인 VPC의 경우, DNS 서버의 IP 주소가 기본 CIDR에 위치합니다. 또한 각 서브넷 범위의 기본에 2를 더한 주소를 VPC의 모든 CIDR 블록에 대해 예약합니다. 자세한 내용은 Amazon DNS 서버 단원을 참조하세요.\n  10.0.0.3: AWS에서 앞으로 사용하려고 예약한 주소.\n  10.0.0.255: 네트워크 브로드캐스트 주소. VPC에서는 브로드캐스트를 지원하지 않으므로, 이 주소를 예약합니다.\n  아까 만들어둔 VPC(10.0.0.0/16)에서 서브넷을 나눠 봅시다.\n 두개의 서브넷을 만들었습니다. (10.0.10.0/24, 10.0.20.0/24)  Routing Table VPC 내 트래픽들의 라우팅 규칙을 설정해야합니다. Routing Table은 기본적으로 VPC에 종속되어 VPC 내 Subnet대역의 라우팅을 결정합니다. 기본적으로 VPC를 생성하면 VPC 대역 내 local 통신을 허용한 상태로 생성됩니다. 이러한 라우팅 테이블에 서브넷을 연결해주어 local 통신만 하는 대역 (Private)과 외부 통신을 하는 대역(Public)등 목적에 맞게 구성합니다.\nprivate, public 라우팅 테이블을 생성하여 서브넷을 할당해봅시다.\n 위 예시처럼 총 3개의 라우팅 테이블 (기본 1, 생성 2)이 만들어졌습니다. 라우팅 규칙 추가는 뒤에서 이어하곘습니다.  Internet Gateway (AKA. igw) VPC의 리소스와 인터넷 간의 통신을 활성화하기 위해 VPC에 연결하는 게이트웨이입니다. igw를 생성하여 라우팅 테이블의 경로를 지정해주면 해당 라우팅 테이블에 연결되어있는 서브넷은 트래픽이 igw를 타고 외부와 통신할 수 있게 됩니다.\n igw를 생성하면 Detached상태로 생성됩니다. 이를 VPC에 연결하여 할당해주면 라우팅테이블에서 리소스를 확인 할 수 있습니다.  라우팅 테이블 경로에 추가하였습니다. 이 라우팅 테이블에 연결된 서브넷들은 이제 외부와 통신이 가능하게 됩니다.\nNAT Gateway 외부와의 연결이 없는 상태의 Private Subnet에서 외부와의 통신이 필요할 때 사용합니다. AWS NAT Gateway 서비스는 내부에서 외부 접근은 가능하지만, 외부에서 내부 접근은 불가능한 SNAT 동작을 합니다. 인터넷으로 나가는 패킷의 Source IP를 NAT Gateway의 Public IP로 바꿔 통신이 가능합니다.\n외에도 인스턴스를 NAT화 시켜 사용하는 방법도 있습니다. (관리의 차이)\n만약 여러 가용 영역에 리소스가 있고 NAT 게이트웨이 하나를 공유하는 경우, NAT 게이트웨이의 가용 영역이 다운되면 다른 가용 영역의 리소스도 인터넷에 액세스할 수 없게 됩니다. 가용 영역과 독립적인 아키텍처를 만들려면 각 가용 영역에 NAT 게이트웨이를 만들고 리소스가 동일한 가용 영역의 NAT 게이트웨이를 사용하도록 라우팅을 구성합니다.\nVPC Endpoint 인터넷 게이트웨이, NAT 디바이스, VPN 연결 또는 AWS Direct Connect 연결 없이도 PrivateLink로 구동하는 지원되는 AWS 서비스 및 VPC 엔드포인트 서비스에 비공개로 연결할 수 있게 합니다. 예를 들어 S3 통신에 사용할 수도 있습니다. VPC의 인스턴스는 서비스의 리소스와 통신하는 데 퍼블릭 IP 주소를 필요로 하지 않습니다. 기본적으로 VPC와 기타 서비스 간의 트래픽은 Amazon 네트워크를 벗어나지 않습니다.\nDHCPset 기본적으로 기본 VPC가 아닌 VPC에 있는 모든 인스턴스는 AWS가 배정하는 확인할 수 없는 호스트 이름을 수신합니다(예: ip-10-0-0-202). 인스턴스에 자체 도메인 이름을 배정하고 최대 4개의 자체 DNS 서버를 사용할 수 있습니다.\n또한 기본 Amazon DNS 서버를 통해 인스턴스에 Private DNS hostname을 할당 받을 수 있습니다.\nVPC 요금 VPC 구성은 별도의 비용이 발생하지 않습니다. 다만 트래픽 미러링이나 VPC flowlog등 별도의 서비스들에 대해서는 비용이 발생합니다. (비쌉니다.)\n결론 VPC를 구성하는 것은 하나의 인프라를 구축함에 있어 기반을 다지는 것과 마찬가지입니다. 최대한 느슨한 구조로 아키텍쳐링하셔야 나중에 수정할 때 편합니다.\n","date":"July 5, 2021","hero":"/posts/aws_beginners/vpc/images/host_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/aws_beginners/vpc/","summary":"\u003cp\u003eAWS를 사용하시려는 모든 유저분들이 간단히 보기에 좋은 내용입니다. AWS Docs는 너무 어려워\u0026hellip;! 그렇다면 들어오세요.\u003c/p\u003e","tags":null,"title":"비기너라면 알아두어야 할 VPC"},{"categories":null,"contents":"찾아보기 쉽게 자주쓰는 명령어를 정리해두었습니다.\nDeployments hands-on  deployments 상세 정보 확인   kubectl describe deployment  kubectl describe deployment \u0026lt;--결과값--\u0026gt; Name: frontend-deployment Namespace: default CreationTimestamp: Fri, 02 Jul 2021 05:01:56 +0000 Labels: \u0026lt;none\u0026gt; Annotations: deployment.kubernetes.io/revision: 1 Selector: name=busybox-pod Replicas: 4 desired | 4 updated | 4 total | 0 available | 4 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25% max unavailable, 25% max surge Pod Template: Labels: name=busybox-pod Containers: busybox-container: Image: busybox888 Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; Command: sh -c echo Hello Kubernetes! \u0026amp;\u0026amp; sleep 3600 Environment: \u0026lt;none\u0026gt; Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Conditions: Type Status Reason ---- ------ ------ Available False MinimumReplicasUnavailable Progressing True ReplicaSetUpdated OldReplicaSets: \u0026lt;none\u0026gt; NewReplicaSet: frontend-deployment-56d8ff5458 (4/4 replicas created) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 96s deployment-controller Scaled up replica set frontend-deployment-56d8ff5458 to 4 틀린 YAML 찾기  apiVersion: apps/v1 kind: deployment \u0026lt;-\u0026gt; Deployment 대문자 metadata: name: deployment-1 spec: replicas: 2 selector: matchLabels: name: busybox-pod template: metadata: labels: name: busybox-pod spec: containers: - name: busybox-container image: busybox888 command: - sh - \u0026quot;-c\u0026quot; - echo Hello Kubernetes! \u0026amp;\u0026amp; sleep 3600 정리 Pod \u0026gt; replicaset \u0026gt; deployment\n","date":"July 2, 2021","hero":"/posts/certification/cka/deployments/images/HO_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/certification/cka/deployments/","summary":"\u003cp\u003e찾아보기 쉽게 자주쓰는 명령어를 정리해두었습니다.\u003c/p\u003e","tags":null,"title":"Deployments hands-on"},{"categories":null,"contents":"찾아보기 쉽게 자주쓰는 명령어를 정리해두었습니다.\nNamespace 네임스페이스는 여러 개의 팀이나, 프로젝트에 걸쳐서 많은 사용자가 있는 환경에서 사용하도록 만들어졌다. 사용자가 거의 없거나, 수 십명 정도가 되는 경우에는 네임스페이스를 전혀 고려할 필요가 없다. 네임스페이스가 제공하는 기능이 필요할 때 사용하도록 하자.\n네임스페이스는 이름의 범위를 제공한다. 리소스의 이름은 네임스페이스 내에서 유일해야하지만, 네임스페이스를 통틀어서 유일할 필요는 없다. 네임스페이스는 서로 중첩될 수 없으며, 각 쿠버네티스 리소스는 하나의 네임스페이스에만 있을 수 있다.\n쿠버네티스는 처음에 네 개의 초기 네임스페이스를 갖는다.\n default : 다른 네임스페이스가 없는 오브젝트를 위한 기본 네임스페이스 kube-system : 쿠버네티스 시스템에서 생성한 오브젝트를 위한 네임스페이스 kube-public : 이 네임스페이스는 자동으로 생성되며 모든 사용자(인증되지 않은 사용자 포함)가 읽기 권한으로 접근할 수 있다. 이 네임스페이스는 주로 전체 클러스터 중에 공개적으로 드러나서 읽을 수 있는 리소스를 위해 예약되어 있다. 이 네임스페이스의 공개적인 성격은 단지 관례이지 요구 사항은 아니다. kube-node-lease : 클러스터가 스케일링될 때 노드 하트비트의 성능을 향상시키는 각 노드와 관련된 리스(lease) 오브젝트에 대한 네임스페이스  \u0026ndash;namespace플래그를 사용하면된다.\nNamespace hands-on  namespace 조회   kubectl get namespace  kubectl get namespace \u0026lt;--결과값--\u0026gt; NAME STATUS AGE default Active 7m23s dev Active 54s finance Active 54s kube-node-lease Active 7m26s kube-public Active 7m26s kube-system Active 7m27s manufacturing Active 54s marketing Active 54s prod Active 54s research Active 54s namespace 내 파드의 개수 확인하기   kubectl get pod \u0026ndash;namespace 네임스페이스 명  kubectl get pod --namespace research NAME READY STATUS RESTARTS AGE test-1 0/1 CrashLoopBackOff 5 5m8s test-2 0/1 CrashLoopBackOff 5 5m8s 특정 네임스페이스 내 Pod 실행시키기 kubectl run pod명 \u0026ndash;image=이미지명 \u0026ndash;namespace 네임스페이스 명  kubectl run redis --image=redis --namespace finance \u0026lt;--결과값--\u0026gt; kubectl get pod --namespace finance NAME READY STATUS RESTARTS AGE redis 1/1 Running 0 62s 특정 네임스페이스 내 Pod 실행시키기 kubectl run pod명 \u0026ndash;image=이미지명 \u0026ndash;namespace 네임스페이스 명  kubectl run redis --image=redis --namespace finance \u0026lt;--결과값--\u0026gt; kubectl get pod --namespace finance NAME READY STATUS RESTARTS AGE redis 1/1 Running 0 62s 네임스페이스 간 파드의 통신 네임스페이스를 하나의 서브넷이라고 생각하면 좀 더 편한거같다. 가령 파드는 기본적으로 격리되지않아 파드간 통신이 원활하지만 네임스페이스를 통해 특정 파드를 선택하는 네트워크 폴리시가 있다면 해당 파드는 네트워크 폴리시에 의해 격리된다. 기본정책이 all deny ","date":"July 1, 2021","hero":"/posts/certification/cka/namespace/images/HO_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/certification/cka/namespace/","summary":"\u003cp\u003e찾아보기 쉽게 자주쓰는 명령어를 정리해두었습니다.\u003c/p\u003e","tags":null,"title":"Namespace hands-on"},{"categories":null,"contents":"찾아보기 쉽게 자주쓰는 명령어를 정리해두었습니다.\nPod hands-on  특정이미지를 통한 pod 생성   kubectl run nginx \u0026ndash;image=nginx (\u0026ndash;restart=Never 옵션을 주면 리붓되지않음)  kubectl run nginx --image=nginx --restart=Never \u0026lt;--결과값--\u0026gt; pod/nginx created 클러스터 내 파드 확인   kubectl get pod -o wide (\u0026ndash;selector 옵션으로 특정 셀럭터기준으로 출력 가능)  kubectl get pod -o wide \u0026lt;--결과값--\u0026gt; NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nginx 1/1 Running 0 4s 10.244.1.3 ip-172-31-41-149.ap-northeast-1.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; pod의 상세 내용 확인 (실패로그 yaml 선언내용 등등 상세 내용 확인 가능)   kubectl describe pod pod명  kubectl describe pod nginx \u0026lt;--결과값--\u0026gt; Name: nginx Namespace: default Priority: 0 Node: ip-172-31-41-149.ap-northeast-1.compute.internal/172.31.41.149 Start Time: Thu, 01 Jul 2021 07:25:12 +0000 Labels: run=nginx Annotations: \u0026lt;none\u0026gt; Status: Running IP: 10.244.1.3 IPs: IP: 10.244.1.3 Containers: nginx: Container ID: docker://204dc60cdb5e56a5ada0088920503dcfeb907276030cf0cdbc3bb75b9188c8e5 Image: nginx Image ID: docker-pullable://nginx@sha256:47ae43cdfc7064d28800bc42e79a429540c7c80168e8c8952778c0d5af1c09db Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; State: Running Started: Thu, 01 Jul 2021 07:25:14 +0000 Ready: True Restart Count: 0 Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-bjkdq (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: kube-api-access-bjkdq: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u0026lt;nil\u0026gt; DownwardAPI: true QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 55s default-scheduler Successfully assigned default/nginx to ip-172-31-41-149.ap-northeast-1.compute.internal Normal Pulling 55s kubelet Pulling image \u0026quot;nginx\u0026quot; Normal Pulled 53s kubelet Successfully pulled image \u0026quot;nginx\u0026quot; in 1.87586268s Normal Created 53s kubelet Created container nginx Normal Started 53s kubelet Started container nginx 클러스터 노드구성 확인   kubectl get node  kubectl get node \u0026lt;--결과값--\u0026gt; NAME STATUS ROLES AGE VERSION ip-172-31-35-14.ap-northeast-1.compute.internal Ready control-plane,master 2d v1.21.1 ip-172-31-37-29.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 2d v1.21.1 ip-172-31-41-149.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 2d v1.21.1 pod 삭제   kubectl delete pod  kubectl delete pod nginx \u0026lt;--결과값--\u0026gt; pod \u0026quot;nginx\u0026quot; deleted pod 업데이트   kubectl edit pod pod명 내용 수정하면 파드가 업데이트 된다.  kubectl edit pod test-nginx-1 \u0026lt;--결과값--\u0026gt; # Please edit the object below. Lines beginning with a '#' will be ignored, # and an empty file will abort the edit. If an error occurs while saving this file will be # reopened with the relevant failures. # apiVersion: v1 kind: Pod metadata: creationTimestamp: \u0026quot;2021-07-01T07:31:48Z\u0026quot; name: test-nginx1 namespace: default resourceVersion: \u0026quot;247954\u0026quot; uid: 5b6b89de-c0e4-4730-90a9-6c2de5468972 spec: containers: - image: nginx:1 -\u0026gt; nginx:2 imagePullPolicy: IfNotPresent name: test-nginx1 ports: - containerPort: 80 protocol: TCP resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-9lg6m readOnly: true dnsPolicy: ClusterFirst enableServiceLinks: true nodeName: ip-172-31-41-149.ap-northeast-1.compute.internal preemptionPolicy: PreemptLowerPriority priority: 0 restartPolicy: Always schedulerName: default-scheduler securityContext: {} serviceAccount: default serviceAccountName: default terminationGracePeriodSeconds: 30 tolerations: - effect: NoExecute key: node.kubernetes.io/not-ready operator: Exists tolerationSeconds: 300 - effect: NoExecute key: node.kubernetes.io/unreachable operator: Exists tolerationSeconds: 300 volumes: - name: kube-api-access-9lg6m projected: defaultMode: 420 sources: - serviceAccountToken: expirationSeconds: 3607 path: token - configMap: items: - key: ca.crt path: ca.crt name: kube-root-ca.crt - downwardAPI: items: - fieldRef: apiVersion: v1 fieldPath: metadata.namespace path: namespace -----상태 / host IP / uptime 등등 중략 ----- ","date":"July 1, 2021","hero":"/posts/certification/cka/pod/images/HO_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/certification/cka/pod/","summary":"\u003cp\u003e찾아보기 쉽게 자주쓰는 명령어를 정리해두었습니다.\u003c/p\u003e","tags":null,"title":"Pod hands-on"},{"categories":null,"contents":"찾아보기 쉽게 자주쓰는 명령어를 정리해두었습니다.\nReplicaSets hands-on  현재 replicaSets 조회   kubectl get replicaset  kubectl get replicaset \u0026lt;--결과값--\u0026gt; NAME DESIRED(원하는 갯수) CURRENT READY AGE new-replica-set 4 4 0 70s replcatsets 상세 구성 확인   kubectl describe replicaset replicaset명  kubectl describe replicaset new-replica-set \u0026lt;--결과값--\u0026gt; Name: new-replica-set Namespace: default Selector: name=busybox-pod Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Replicas: 4 current / 4 desired Pods Status: 0 Running / 4 Waiting / 0 Succeeded / 0 Failed Pod Template: Labels: name=busybox-pod Containers: busybox-container: Image: busybox777 Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; Command: sh -c echo Hello Kubernetes! \u0026amp;\u0026amp; sleep 3600 Environment: \u0026lt;none\u0026gt; Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulCreate 3m46s replicaset-controller Created pod: new-replica-set-tx56t Normal SuccessfulCreate 3m46s replicaset-controller Created pod: new-replica-set-24jhd Normal SuccessfulCreate 3m46s replicaset-controller Created pod: new-replica-set-5xnp7 Normal SuccessfulCreate 3m46s replicaset-controller Created pod: new-replica-set-qgzbt replicaset으로 생성된 pod들은 pod를 삭제해도 라이플 사이클에 의해 다시 살아나니, replicaset 자체를 지워야됨   kubectl delete replicaset new-replica-set  Replicaset yaml로 생성 (아래 파일 수정)  apiVersion: v1 \u0026lt;-\u0026gt; apps/v1 kind: ReplicaSet metadata: name: replicaset-1 spec: replicas: 2 selector: matchLabels: tier: frontend template: metadata: labels: tier: frontend spec: containers: - name: nginx image: nginx Replicaset yaml로 생성 (아래 파일 수정)  apiVersion: apps/v1 kind: ReplicaSet metadata: name: replicaset-2 spec: replicas: 2 selector: matchLabels: tier: frontend \u0026lt;-\u0026gt; tier가 일치하지 않음 template: metadata: labels: tier: nginx \u0026lt;-\u0026gt; frontend spec: containers: - name: nginx image: nginx Replicaset 롤링업데이트   kubectl edit replicaset replicaset명  kubectl edit replicaset replicaset명 \u0026lt;내용 수정 후\u0026gt; kubectl delete pod pod명 (새로 구성된 내용을 생성하기 위해 구버전 pod를 삭제함) Replicaset 스케일 조절 (확장) (위 edit 명령어로 갯수를 늘려도되지만 scale 명령어 사용해봄)   kubectl scale rs replicaset명 \u0026ndash;replicas=8  kubectl scale rs new-replica-set --replicas=8 Replicaset 스케일 조절 (축소) (위 edit 명령어로 갯수를 늘려도되지만 scale 명령어 사용해봄)   kubectl scale rs replicaset명 \u0026ndash;replicas=2  kubectl scale rs new-replica-set --replicas=2 ","date":"July 1, 2021","hero":"/posts/certification/cka/replicasets/images/HO_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/certification/cka/replicasets/","summary":"\u003cp\u003e찾아보기 쉽게 자주쓰는 명령어를 정리해두었습니다.\u003c/p\u003e","tags":null,"title":"ReplicaSets hands-on"},{"categories":null,"contents":"AWS EC2의 nitro 타입과 세대 변경 간 확인해야되는 부분 등 경험을 기록해봤습니다.\n배경 AWS에서 t2와 같은 구세대 인스턴스를 최신 세대의 인스턴스로 마이그레이션하는 고객들의 기억을 되살리며 메모해둡니다.\nEC2 instance의 가상화 기술은 Xen PV 으로 시작하여 Xen HVM 을거쳐 Nitro 까지 발전을 거듭해왔습니다 AWS의 인스턴스는 크게 Xen 기반의 구세대 인스턴스와 Nitro 시스템 (KVM)기반의 신세대 인스턴스로 나뉩니다.\n무슨 차이가 있는지? 짧고 굵게 설명하자면, 이전 세대 대비 저렴한 비용 그와 반대되는 성능적 차이가 있습니다. 메모리, CPU의 할당을 관리하고 대부분의 워크로드에있어서 베어 메탈과 거의 유사한 성능을 제공하는 하이퍼바이저라고 설명합니다.\n5세대 인스턴스들은 모두 Nitro 시스템이 도입되어 있기에 이전 세대의 인스턴스와는 다른 드라이버들이 존재합니다.\n  로컬 NVMe 스토리지\n 새로운 C5d, M5d 및 베어 메탈 EC2 인스턴스에는 Xen 가상화 I3 및 F1 인스턴스에도 사용되는 Nitro 로컬 NVMe 스토리지 구성 요소가 포함됩니다. 이 구성 요소는 PCI 인터페이스를 통해 고속 로컬 스토리지에 대한 직접 액세스를 제공하며, 모든 데이터를 전용 하드웨어를 사용하여 투명하게 암호화합니다. 또한 스토리지 디바이스와 EC2 인스턴스를 하드웨어 레벨에서 분리하여 베어 메탈 인스턴스에서 로컬 NVMe 스토리지의 이점을 활용할 수 있도록 합니다.    Nitro 보안 칩\n AWS 서버 설계에 포함되는 구성 요소로, 하드웨어 리소스를 지속적으로 모니터링하고 보호하며 시스템을 부팅할 때마다 독립적으로 펌웨어를 확인합니다.    Nitro 하이퍼바이저\n 메모리 및 CPU 할당을 관리하고 대부분의 워크로드에 베어 메탈과 거의 유사한 성능(Netflix의 Brendan Gregg는 이 성능을 1% 미만으로 벤치마킹함)을 제공하는 대기 휴지 상태의 씬 하이퍼바이저입니다.    네트워킹\n 각 VPC(가상 프라이빗 클라우드) 내의 소프트웨어 정의 네트워크에 대한 하드웨어 지원, 향상된 네트워킹 및 탄력적 네트워크 어댑터(ENA)를 제공합니다.    탄력적 블록 스토리지\n CPU 집약형 암호화 작업을 포함한 하드웨어 EBS 처리 기능을 제공합니다. 스토리지, 네트워킹 및 보안 기능을 하드웨어로 이동하면 베어 메탈 및 가상 인스턴스 유형에서 다음과 같은 이점을 실현할 수 있습니다.    가상 인스턴스의 경우 하이퍼바이저의 역할이 크게 감소하므로 모든 호스트의 CPU 성능 및 메모리를 게스트 운영 체제에 제공할 수 있습니다.\n  베어 메탈 인스턴스는 하드웨어에 완벽하게 액세스할 수 있을 뿐 아니라 가상 EC2 인스턴스와 동일한 유연성 및 기능 세트(예: CloudWatch 지표, EBS 및 VPC)를 활용할 수 있습니다.\n  AWS NitroSystem-1\nAWS NitroSystem-2\n구구절절한것들 말고 실질적으로 이전 세대에서 신세대 인스턴스로 옮기는데 확인이 필요한 부분은 아래 두가지 입니다.\n1. Network 드라이버 ENA를 도입했습니다. 기본적은 네트워크모듈인 ENA (Elastic Network Adapter)는 기존 ENI보다 향상된 네트워킹 성능을 제공합니다. 가령, 네트워크 지연시간을 줄이고, PPS 성능이 높아진 모듈이라고 생각하면 편할듯합니다.\n2. Storage 드라이버 Nitro 시스템 기반 인스턴스에서는 EBS 볼륨이 NVMe(Non-Volatile Memory express) 블록 디바이스로 표시됩니다.\nNVMe는 PCIe 버스를 통해 작동 하므로 특성은 하드디스크가 아닌 고속 메모리에 가깝다고 할 수 있습니다.\nNVMe 볼륨을 사용하기에 그에맞는 드라이버가 필요합니다.\n3. [check point]  내 인스턴스의 버전 확인 내 인스턴스의 uptime을 확인해야 합니다. 기본적으로 4세대 인스턴스에는 최신 세대 인스턴스 유형을 지원하는 드라이버 및 구성이 포함되어있지 않았습니다. 2018년 8월 이후의 인스턴스에는 최신 세대 인스턴스 유형을 지원하는 드라이버 및 구성이 포함됩니다.  결론 위에서 인스턴스 버전을 확인해본 결과,, 2018년 8월 이전에 생성된 인스턴스라면 위 드라이버들을 수동으로 설치해줘야 합니다.\n  Window 인스턴스를 업그레이드하려는 경우 인스턴스에서 어느 네트워크 드라이버가 실행되고 있는지 확인해야 합니다. PV 네트워크 드라이버는 사용자가 원격 데스크톱을 사용하여 인스턴스에 액세스할 수 있게 해줍니다. Windows Server 2008 R2부터 인스턴스는 AWS PV, intel Network Adapter 또는 Enhanced Networking 드라이버를 사용합니다. Windows Server 2003 및 Windows Server 2008의 인스턴스는 Citrix PV 드라이버를 사용합니다.\n  Linux 인스턴스를 업그레이드 하는 경우 ENA(Elastic Network Adapter) enaSupport 속성이 활성화되어있는지 확인해야합니다.\n  가능하다면 NitroInstanceChecks script 스크립트 실행하시는게 제일 편합니다. AWS에서 제공하는 스크립트를 실행하고 업그레이드를 위해 무엇이 필요한지 확인하면됩니다.\n  NitroInstanceChecks링크\n 위 스크립트는 아래 OS버전에서 지원합니다.  Red Hat 계열: Red Hat Linux, Red Hat Enterprise Linux, CentOS Amazon Linux, Amazon Linux 2 Debian 계열: Debian, Ubuntu    모든 변경사항을 발생시키기 전 AMI 풀백업은 필수 업그레이드가 모종의 이유로 실패할 경우를 대비하여 항상 백업본을 유지한 채 작업을 진행합시다.\n실제로 점검시간 내 세대변경 작업이 완료되지않아 이슈가 발생한 적이 있었습니다. Dev서버였기에 가장 최근의 백업본이 3일전의 이미지였기에 해당 dev서버의 root 볼륨을 테스트인스턴스에 연결해서 수정했던 기억이 나네요. 스크립트를 돌려보고 작업헀어야헀는데, 안일했습니다. 덕분에 점검시간을 30분이나 늘렸으니 말이죠.\n마지막으로 간혹 5세대 인스턴스의 NVMe에서 timeout에 의해 I/O작업이 멈춘 이슈도 있었습니다. 대충 이런 순서로 장애가 발생했던 것으로 기억합니다.\nInstance Hardware 이슈 발생 -\u0026gt; 이슈타임 간 EBS 이슈 발생 -\u0026gt; NVMe Timeout -\u0026gt;Instance Hardware 이슈 해소 -\u0026gt; NVMe timeout으로 인한 부팅 실패 -\u0026gt; 상태유지 -\u0026gt; 담당자 아침에 출근하여 리붓으로 해소\n일단은 부트파라미터에서 nvme.io_timeout값을 최대값으로 변경하여 이후 이슈는 없었지만 악재의 악재가 겹치는 상황이였기에 당시 꽤나 당황스러운 이슈였습니다.\n겪었던 사례들을 메모해봤습니다.\n감사합니다.\n","date":"June 30, 2021","hero":"/posts/cloud/aws/awsgeneration/images/host_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/cloud/aws/awsgeneration/","summary":"\u003cp\u003eAWS EC2의 nitro 타입과 세대 변경 간 확인해야되는 부분 등 경험을 기록해봤습니다.\u003c/p\u003e","tags":null,"title":"세대를 교체중입니다. -AWS"},{"categories":null,"contents":"Service의 LB와 Ingress의 차이가 이해되지 않아 간단하게 정리해서 기록해두었습니다.\nService (LB) vs Ingress 우선 두가지 모두 내 파드 안에 띄워놓은 컨테이너들(애플리케이션)을 노출하고자할때 사용하는게 맞다. 앞서 설명하였듯이, Pod의 상태는 매우 유동적이기에 고정적인 IP나 Endpoint가 필요하기 때문에 사용하는 것 또한 맞다.\n그럼 이 둘을 어떻게 구분지으면 될까? 각각 속성을 알아보자.\nService와 Ingress 구분 Service와 Ingress 모두 부하분산처리를 한다는 점은 동일하다. 가장 큰 차이는 어떻게 서비스를 외부에 노출하느냐이다.\n  LB의 경우 : CSP(Cloud Service Provider)에서 제공하는 LB서비스가 필요하다 가령, AWS의 ELB, GCP의 GLB등 Cloud Load Balancer을 사용하거나 온프레미스 환경에서는 metalLB을 설치하여야 한다. 서비스 당 1개의 public IP를 부여받아야 하는 부분이다.\n  Ingress의 경우 : 서비스들의 상위 객체 개념으로 URL mapping하여 요청에 대한 경로를 지정해준다.\n  그러니까 비교 대상이 될 수 없다. LB는 서비스지만 Ingress는 그런 서비스들에 대해 라우팅의 역할을 담당하기 때문에 상위 객체로 인식하면 될듯하다.\n간단하게 Ingress L7, Service LB L4 정도로 ..!\n테스트 kubectl create deployment hello-app --image=gcr.io/google-samples/hello-app:1.0 kubectl expose deployment hello-app --port=8080. kubectl get service \u0026lt;--결과값--\u0026gt; NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hello-app ClusterIP 10.43.254.28 \u0026lt;none\u0026gt; 8080/TCP 6s hello-app 애플리케이션을 배포하고 expose하여 서비스로 노출시킨다.\nNGINX 컨트롤러 사용 NGINX 컨트롤러는 외부에서 액세스할 수 있도록 노출되어야 한다. NGINX 컨트롤러 서비스 중 서비스 type: LoadBalancer를 사용하면 컨트롤러를 노출시킬 수 있다.\nhelm install nginx-ingress stable/nginx-ingress --set rbac.create=true kubectl get service \u0026lt;--결과값--\u0026gt; NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hello-app ClusterIP 10.43.254.28 \u0026lt;none\u0026gt; 8080/TCP 3m28s kubernetes ClusterIP 10.43.240.1 \u0026lt;none\u0026gt; 443/TCP 7m10s nginx-ingress-controller LoadBalancer 10.43.246.253 34.132.63.140 80:32210/TCP,443:30476/TCP 54s nginx-ingress-default-backend ClusterIP 10.43.248.107 \u0026lt;none\u0026gt; 80/TCP 54s  nginx-ingress-default-backend : 모든 URL 경로를 처리하고 NGINX 컨트롤러를 호스트하는 서비스이다. 서비스에 정상적으로 Nginx Ingress 가 배포된 것을 확인헀다면 테스트를 위한 경로 규칙을 정의해보자.  apiVersion: extensions/v1beta1 kind: Ingress metadata: name: ingress-resource annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/ssl-redirect: \u0026quot;false\u0026quot; spec: rules: - http: paths: - path: /hello backend: serviceName: hello-app servicePort: 8080 간단하게 34.132.63.140/hello에 대한 요청을 백엔드의 hello-app서비스의 8080으로 요청을 흘려주는 인그레스 리소스를 생성해보았다. 적용 해보자\nkubectl apply -f ingress-resource.yaml kubectl get ingress ingress-resource 이제 테스트 페이지를 확인해보자.\n정상경로 접근 시 결과 다른경로 접근 시 결과 (default backend 동작 확인) 간단하게 LB와 Ingress의 차이를 확인해보았다.\n","date":"June 29, 2021","hero":"/posts/kubernetes/k8singress/images/CKA_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/kubernetes/k8singress/","summary":"\u003cp\u003eService의 LB와 Ingress의 차이가 이해되지 않아 간단하게 정리해서 기록해두었습니다.\u003c/p\u003e","tags":null,"title":"k8s(Ingress)"},{"categories":null,"contents":"컨테이너의 볼륨관리와 나아가 kubernetes의 볼륨은 어떻게 관리되는지 기록해봤습니다.\n배경 컨테이너의 파일은 호스트의 파일 시스템에 마운트되어 있다. 컨테이너는 이미지로부터 만들어지므로 크게 다음의 호스트 파일 경로에 마운트된다.\n 이미지의 파일 내용을 저장하는 호스트 파일 경로(이미지는 실제로 레이어로 구성되므로 여러 경로 사용) 컨테이너 구동 이후 변경 사항을 저장하기 위한 호스트 파일 경로  이 외에 \u0026ndash;mount 옵션을 이용해서 호스트 파일 시스템이나 도커 볼륨에 마운트 할 수 있다.\ndocker inspect 명령어를 사용하면 호스트 파일 시스템에 마운트된 경로를 확인할 수 있다.\n그러면 쿠버네티스는 어떤 개념의 볼륨들이 있고, 어떻게 사용하는지 궁금해졌다.\n도커 볼륨 컨테이너 내의 디스크는 임시 디스크이다. 그렇기에 컨테이너가 터질때마다 컨테이너 내 데이터가 사라질 수 밖에 없다.\n그렇기에 도커 볼륨을 이용해서 host directory에서 데이터를 관리하는 방법이 생겼다. 이렇게 되면 컨테이너를 지워도 도커 볼륨과 컨테이너를 연결한다면 데이터는 그대로 유지할 수 있게되었다. 그렇지만 결국 도커 볼륨을 사용한다는 것은 도커에 의해 관리된다는 걸 뜻할 수 있다 (어떤 컨테이너에 연결되어있는지 등 관리가 편하다.)\ndocker volume create 위 명령어로 볼륨을 생성하면 생성된 볼륨은 호스트 디렉토리인 /var/lib/docker/volumes/ 에 저장된다.\n말고 바로 Host bind Mount하여 사용하는 방식도 있다. 이 방법은 기능적으로는 docker volume과 유사하지만 도커의 관리 없이 Host Directory와 마운트를 하다 보니\n컨테이너에서 호스트의 파일 시스템에 접근하여 컨테이너에 지정된 파일이 아닌 다른 파일을 삭제/추가/수정할 수 있다는 것이 단점이다.\n이 기능은 호스트 시스템의 비 Docker 프로세스에 영향을 주는 것을 포함하여 보안에 영향을 미칠 수 있기에 권장하지 않고있다.\n이외에도 메모리에 데이터를 저장하는 tmpfs 마운트 방식도 있다. 마치 쿠버의 secret처럼 메모리에 저장되며 휘발성을 따라간다.\n여기까진 도커의 볼륨 개념을 정리했다면 쿠버에서는 어떤 유형의 볼륨을 지원하는지 체크해보자.\nk8s 볼륨 파드는 여러 볼륨 유형을 동시에 사용할 수 있다. 임시 볼륨 유형은 파드의 수명을 갖지만, 퍼시스턴트 볼륨은 파드의 수명을 넘어 존재한다.\n파드가 더 이상 존재하지 않으면, 쿠버네티스는 임시(ephemeral) 볼륨을 삭제하지만, 퍼시스턴트(persistent) 볼륨은 삭제하지 않는다. 볼륨의 종류와 상관없이, 파드 내의 컨테이너가 재시작되어도 데이터는 보존된다.\n볼륨을 사용하려면, .spec.volumes 에서 파드에 제공할 볼륨을 지정하고 .spec.containers[*].volumeMounts 의 컨테이너에 해당 볼륨을 마운트할 위치를 선언한다.\n퍼시스턴트 볼륨과 퍼시스턴트 볼륨 클래임 퍼시스턴트볼륨 (PV)은 관리자가 프로비저닝하거나 스토리지 클래스를 사용하여 동적으로 프로비저닝한 클러스터의 스토리지이다. 노드가 클러스터 리소스인 것처럼 PV는 클러스터 리소스이다. PV는 Volumes와 같은 볼륨 플러그인이지만, PV를 사용하는 개별 파드와는 별개의 라이프사이클을 가진다. 이 API 오브젝트는 NFS, iSCSI 또는 클라우드 공급자별 스토리지 시스템 등 스토리지 구현에 대한 세부 정보를 담아낸다.\n퍼시스턴트볼륨클레임 (PVC)은 사용자의 스토리지에 대한 요청이다. 파드와 비슷하다. 파드는 노드 리소스를 사용하고 PVC는 PV 리소스를 사용한다. 파드는 특정 수준의 리소스(CPU 및 메모리)를 요청할 수 있다. 클레임은 특정 크기 및 접근 모드를 요청할 수 있다(예: ReadWriteOnce, ReadOnlyMany 또는 ReadWriteMany로 마운트 할 수 있음. AccessModes )\n정리해보자면 퍼시스턴트 볼륨은 그냥 디스크 그 자체이다. 어떤 파드에 어느정도의 볼륨을 파티셔닝할지는 퍼시스턴트 볼륨 클래임을 통해 생성하고 접근 방식을 지정한다.\n퍼시스턴트볼륨클레임(PersistentVolumeClaim)을 사용하도록 파드를 설정해보자.\nPV-PVC 정적 프로비저닝 그전에 우선 /mnt/data에 index.html파일을 하나 생성해두었다.\nvi test-pv.yaml ---------------------------- apiVersion: v1 kind: PersistentVolume metadata: name: test-pv-volume labels: type: local spec: storageClassName: manual capacity: storage: 10Gi accessModes: - ReadWriteOnce hostPath: path: \u0026quot;/mnt/data\u0026quot; 퍼시스턴스 볼륨 구성 내용은 위와 같다. (10Gi, R/W_Once, Path= /mnt/data) 스토리지 클래스 네임을 정의하여 퍼시스턴트볼륨클래임의 바인딩을 사는데 사용한다.\n일단 PV를 생성하고 조회해보자.\nkubectl apply -f test-pv.yaml kubectl get pv \u0026lt;--결과값--\u0026gt; NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE test-pv-volume 10Gi RWO Retain Available manual 1m PV를 조회했더니 뭔가 항목이 많이보인다. 각 항목이 의미하는 바는 아래와 같다.\n NAME : PV 명 CAPACITY : PV 용량 ACCESS MODES : 접근 모드 설정 (단일노드 r/w/멀티노드 r,r/w) RECLAIM POLICY : 회수 정책 (retain, Recycle, Delete) STATUS : 상태 CLAIM : 현재 바인딩되어있는 클레임 STORAGECLASS : 특정 클래스의 PV를 가지면 해당 클래스에 요청하는 PVC만 바인딩된다.  vi test-pv-claim.yaml ---------------------------- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: test-pv-claim spec: storageClassName: manual accessModes: - ReadWriteOnce resources: requests: storage: 5Gi 퍼시스턴스 볼륨 클래임 구성 내용은 위와 같다. (5Gi) 마찬가지로 퍼시스턴트 볼륨 클래임을 생성하고 조회해보자.\nkubectl apply -f test-pv-claim.yaml kubectl get pvc \u0026lt;--결과값--\u0026gt; NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE test-pv-claim Bound test-pv-volume 5Gi RWO manual 7s 다시 pv를 조회해보면, Status와 CLAIM이 업데이트된걸 볼 수 있다.\nkubectl get pv \u0026lt;--결과값--\u0026gt; NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE test-pv-volume 5Gi RWO Retain Bound default/test-pv-claim manual 1m 그럼 이제 생성한 클레임을 파드에 붙여보자.\napiVersion: v1 kind: Pod metadata: name: test-pv-pod spec: volumes: - name: test-pv-storage persistentVolumeClaim: claimName: test-pv-claim containers: - name: test-pv-container image: nginx ports: - containerPort: 80 name: \u0026quot;http-server\u0026quot; volumeMounts: - mountPath: \u0026quot;/usr/share/nginx/html\u0026quot; name: test-pv-storage kubectl apply -f test-pv-pod.yaml kubectl get pod test-pv-pod \u0026lt;--결과값--\u0026gt; 윽, 캡쳐를 못했다. 혹여 파드가 pending상태라면 kubectl describe를 통해 파드의 상태를 확인해보면 로그가 딱 보일것이다. exec 명령어로 쉘에 접근하여 실제 hostpath(/mnt/data)볼륨으로부터 index.html를 제공받았는지 체크해보자.\nkubectl exec -it test-pv-pod -- /bin/bash curl http://localhost/ Hello from Kubernetes storage exit host에 생성해둔 index.html이 잘불러와진다.\n동적 프로비저닝 동적 볼륨 프로비저닝의 구현은 storage.k8s.io API 그룹의 StorageClass API 오브젝트를 기반으로 한다. 클러스터 관리자는 볼륨을 프로비전하는 볼륨 플러그인 (프로비저너라고도 알려짐)과 프로비저닝시에 프로비저너에게 전달할 파라미터 집합을 지정하는 StorageClass 오브젝트를 필요한 만큼 정의할 수 있다.\n그러기 위해선 스토리 클래스 오브젝트를 사전에 생성해 두어야 한다.\n동적 프로비저닝 오브젝트 예시 (Googlecloud) apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: slow provisioner: kubernetes.io/gce-pd parameters: type: pd-standard apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: fast provisioner: kubernetes.io/gce-pd parameters: type: pd-ssd 동적 프로비저닝 사용 사용자는 PersistentVolumeClaim 오브젝트의 storageClassName 필드를 사용해야 한다. 이 필드의 값은 관리자가 구성한 StorageClass 의 이름과 일치해야 한다.\n예를 들어 \u0026ldquo;fast\u0026rdquo; 스토리지 클래스를 선택하려면 다음과 같은 PersistentVolumeClaim 을 생성한다.\napiVersion: v1 kind: PersistentVolumeClaim metadata: name: claim1 spec: accessModes: - ReadWriteOnce storageClassName: fast resources: requests: storage: 30Gi 이런 식으로 클레임을 구성하면 자동으로 볼륨이 프로비저닝된다.\n그렇담 애초에 스토리지 클래스가 지정되지않은 모든 클래임들이 자동으로 동적 프로비저닝을 사용하면 관리하기 얼마나 편할까? master-cluster에서 설정이 가능하다.\nstorageclass.kubernetes.io/is-default-class 어노테이션을 추가해서 특정 StorageClass 를 기본으로 표시할 수 있다. 기본 StorageClass 가 클러스터에 존재하고 사용자가 storageClassName 를 지정하지 않은 PersistentVolumeClaim 을 작성하면, DefaultStorageClass 어드미션 컨트롤러가 디폴트 스토리지 클래스를 가리키는 storageClassName 필드를 자동으로 추가한다.\n끝 ~_~\n","date":"June 29, 2021","hero":"/posts/kubernetes/k8svolume/images/CKA_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/kubernetes/k8svolume/","summary":"\u003cp\u003e컨테이너의 볼륨관리와 나아가 kubernetes의 볼륨은 어떻게 관리되는지 기록해봤습니다.\u003c/p\u003e","tags":null,"title":"k8s(Volume)"},{"categories":null,"contents":"GKE를 생성해서 kubectl에 익숙해져보자.\nGKE(google Kubernetes Engine) 기존 쿠버네티스와 동일하게 Master(Control Plane)과 Worker Node로 구성되어있으며, GCP 관리형 서비스이기에 노드 확장 등의 편리함이 있다. (arg. AWS EKS\u0026hellip;) 그저, 위치와 k8s 버전, Network (VPC) 환경과 IP 대역만 설정하면 내부에 알아서 k8s cluster를 생성해준다.\nGKE Cluster 생성 지난 번과 동일하게 GKE Cluster를 gcloud 명령어를 통해 생성해준다.\ngcloud container clusters create dominic-gke-1 \u0026lt;---결과값---\u0026gt; kubeconfig entry generated for dominic-gke-1. NAME LOCATION MASTER_VERSION MASTER_IP MACHINE_TYPE NODE_VERSION NUM_NODES STATUS dominic-gke-1 us-central1-b 1.19.10-gke.1600 34.71.29.146 e2-medium 1.19.10-gke.1600 3 RUNNING 웹 배포 지난번과 같이 인증 이후 nginx를 배포한다.\nkubectl create deployment nginx --image=nginx:1.10.0 \u0026lt;---결과값---\u0026gt; deployment.apps/nginx created 배포가 완료되었다면, 정상적으로 파드에 nginx 컨테이너가 잘 계신지 확인해보자.\nkubectl get pods \u0026lt;---결과값---\u0026gt; NAME READY STATUS RESTARTS AGE nginx-56cd7f6b6-2nc6l 1/1 Running 0 59s 마찬가지로 expose 명령어를 통해 서비스를 생성하여 외부로 컨테이너를 노출 시켜보자.\nkubectl expose deployment nginx --port 80 --type LoadBalancer \u0026lt;---결과값---\u0026gt; service/nginx exposed Kubernetes가 백그라운드에서 공개 IP 주소를 사용하는 LB를 통해 nginx pod로 요청이 라우팅 될 것이다. 방금 만든 서비스를 확인해보자..\nkubectl get services \u0026lt;---결과값---\u0026gt; NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.3.240.1 \u0026lt;none\u0026gt; 443/TCP 14m nginx LoadBalancer 10.3.255.47 34.122.123.30 80:31317/TCP 77s 결과\npod 상세 조회해보기 kubectl describe pods 명령어를 통해 해당 파드의 ip주소 및 이벤트 로그등 여러 정보를 확인할 수 있다. 파트에 뭔가 문제가 생겼다면 가장 먼저 확인해보게 될 명령어이다.\nkubectl logs 명령어를 통해서는 로그를 확인할 수 있다. -f 옵션을 주어 실시간으로 로그스트림을 확인하는 것도 가능하다. 가령 다른 터미널을 하나 열어 -f로 로그를 모니터링하고 요청이 정상적으로 들어오는지 체크해볼 수 있다.\n포드와 상호작용하기 포드 내 컨테이너에서 셀을 사용할 수 있다면, kubectl exec 명령어를 사용하여 셸 접근을 할 수 있다. 로그나 파드에서 컨테이너의 상태가 좋지 않을 때, 컨테이너 내 작업이 필요할 경우 유용하다.\n서비스 서비스의 라벨 셀랙터를 사용하여 제한된 포드 집합을 외부에 노출해보자.\n서비스 만들기 kind: Service apiVersion: v1 metadata: name: \u0026quot;nginx\u0026quot; spec: selector: app: \u0026quot;nginx\u0026quot; name: \u0026quot;dominic\u0026quot; ports: - protocol: \u0026quot;TCP\u0026quot; port: 443 targetPort: 443 nodePort: 31000 type: NodePort NodePort 타입으로 외부트래픽을 31000에서 컨테이너의 443으로 전달하도록 service.yaml을 작성하였다. Nodeport를 사용할때는 포트가 겹치지 않도록 구성해야 충돌이 발생하지 않는다. 별도의 LB를 달지 않았기에 노도의 외부 IP와 31000 포트를 사용하여 파드 내 컨테이너에 접근해보자.\ncurl -k https://\u0026lt;EXTERNAL_IP\u0026gt;:31000 되시는 분은 오점을 찾으신거고, 안되셔서 당황하셨으면 아직 service에 대해 공부가 조금 더 필요한거다. 안되는 이유를 아시면 넘어가시고 아니라면 아래 명령어를 통해 생성한 서비스의 구성을 확인해보자.\nkubectl describe services nginx\n답은 service의 selector에 있다. 현재 우리의 nginx 파드는 엔드포인트가 없다 왜냐 라벨이 지정되어있지 않기에 서비스의 셀렉터에 감지되지 않았기 때문이다. 라벨을 추가해주자.\nkubectl label pods nginx-56cd7f6b6-2nc6l 'app:nginx' kubectl label pods nginx-56cd7f6b6-2nc6l 'name:dominic' 이제 파드에 정확히 라벨을 지정하였으니, 엔드포인트가 확인 될 것이다.\n결과\n결론 쿠버네티스에서 서비스는 파드의 논리적 집합과 그것들에 접근할 수 있는 정책을 정의하는 추상적 개념이다. (때로는 이 패턴을 마이크로-서비스라고 한다.) 서비스가 대상으로 하는 파드 집합은 일반적으로 셀렉터가 결정한다. 물론 셀렉터가 없는 서비스도 가능하다.\n가령 프로덕션 환경에서는 외부 데이터베이스 클러스터를 사용하려고 하지만, 테스트 환경에서는 자체 데이터베이스를 사용한다.\n또는 한 서비스에서 다른 네임스페이스 또는 다른 클러스터의 서비스를 지정하려고 한다.\n혹은 워크로드를 쿠버네티스로 마이그레이션하고 있다. 해당 방식을 평가하는 동안, 쿠버네티스에서는 백엔드의 일부만 실행한다. 간혹 몇몇의 케이스에 따라 별도의 파드 셀렉터 없이 서비스를 정의하는 것이 가능하다.\n사례 1. apiVersion: v1 kind: Service metadata: name: my-service spec: ports: - protocol: TCP port: 80 targetPort: 9376 이 서비스에는 셀렉터가 없으므로, 해당 엔드포인트 오브젝트가 자동으로 생성되지 않는다. 엔드포인트 오브젝트를 수동으로 추가하여, 서비스를 실행 중인 네트워크 주소 및 포트에 서비스를 수동으로 매핑할 수 있다.\n사례 2. apiVersion: v1 kind: Endpoints metadata: name: my-service subsets: - addresses: - ip: 192.0.2.42 ports: - port: 9376 셀렉터가 없는 서비스에 접근하면 셀렉터가 있는 것처럼 동일하게 작동한다. 위의 예에서, 트래픽은 YAML에 정의된 단일 엔드 포인트로 라우팅된다. 192.0.2.42:9376 (TCP)\nExternalName 서비스는 셀렉터가 없고 DNS명을 대신 사용하는 특수한 상황의 서비스이다.\n","date":"June 28, 2021","hero":"/posts/cloud/gcp/k8sgke-service/images/CKA_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/cloud/gcp/k8sgke-service/","summary":"\u003cp\u003eGKE를 생성해서 kubectl에 익숙해져보자.\u003c/p\u003e","tags":null,"title":"k8s(GKE-Service)"},{"categories":null,"contents":"GKE를 생성해서 kubectl에 익숙해져보자.\nGKE(google Kubernetes Engine) 기존 쿠버네티스와 동일하게 Master(Control Plane)과 Worker Node로 구성되어있으며, GCP 관리형 서비스이기에 노드 확장 등의 편리함이 있다. (arg. AWS EKS\u0026hellip;) 그저, 위치와 k8s 버전, Network (VPC) 환경과 IP 대역만 설정하면 내부에 알아서 k8s cluster를 생성해준다.\nnode pool node에 대한 위치, 수량, 스펙, 운영체제, 셀프힐링, 노드 업그레이드 정책, 최대 Pod/node 갯수를 선택한다.\nGKE 클러스터 생성 세상이 이렇게 좋아졌다. 짧은 CLI 한줄로 GKE 클러스터를 생성할 수 있다.\ngcloud container clusters create dominic-gke-1 \u0026lt;---결과값---\u0026gt; kubeconfig entry generated for dominic-gke-1. NAME LOCATION MASTER_VERSION MASTER_IP MACHINE_TYPE NODE_VERSION NUM_NODES STATUS dominic-gke-1 us-central1-a 1.19.9-gke.1900 비-밀-임 e2-medium 1.19.9-gke.1900 3 RUNNING 3대의 노드로 이뤄진 GKE가 생성되었다. 클러스터 사용자 인증 정보가 필요하다.\nGKE 클러스터 인증정보 갱신 gcloud container clusters get-credentials dominic-gke-1 이제 GKE 셋팅은 완료하였으니, 뭐라도 배포해보자 제일 좋아하는 Hello, world를\u0026hellip;kubtctl create deployment를 통해 새 배포를 만들어준다.\nGKE deplotyment kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:1.0 배포가 정상적으로 이뤄졌다면 파드가 올라와있는지 확인해보자.\nkubectl get pod -o wide \u0026lt;---결과값---\u0026gt; NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES hello-server-76d47868b4-q5mrf 1/1 Running 0 109s 10.40.0.6 gke-dominic-gke-1-default-pool-601c4b2c-tqvk \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 파드가 gke-dominic-gke-1-default-pool-601c4b2c-tqvk라는 노드에 배포되어 1개의 컨테이너가 잘 실행되어있다.\nGKE expose serivce kubectl expose 명령어로 서비스를 노출해서 체크해보자\nkubectl expose deployment hello-server --type=LoadBalancer --port 8080 \u0026lt;---결과값---\u0026gt; service/hello-server exposed kubectl get service로 확인해보면\nkubectl get services \u0026lt;---결과값---\u0026gt; NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE hello-server LoadBalancer 10.43.246.172 \u0026lt;pending\u0026gt; 8080:32709/TCP 33s 생성한 service의 IP를 알 수 있다. 아직 Pending이면 우선 기다려보자. 내 서비스 LB의 IP는 34.134.44.184다.\nGKE service test 이렇게 외부에서 8080 포트를 통해 접근했을 때, 파드 내 컨테이너의 Hello, world web이 접근되는걸 볼 수 있다.\n깔끔하다. CNI도 고민없이 그냥 GKE의 CNI를 사용했다.\nGKE 기본 CNI 환경 \nGKE의 CNI를 사용하는 경우 가상 이더넷 기기(veth) 쌍의 한쪽 끝은 네임스페이스의 pod에 연결되고 다른 한쪽 끝은 Linux 브리지 기기 cbr0에 연결된다.\n이 경우 다음 명령어를 실행하면 cbr0에 연결된 pod의 MAC 주소가 표시된다.\narp -n 또한 이전 k8s-network에서 확인했듯이 brctl 명령어를 통해 cbr0에 연결된 각 veth 쌍의 루트 네임스페이스가 확인된다.\nbrctl show cbr0 GKE를 한번 써본 것으로 좀 더 kube~명령어에 익숙해진 느낌이랄까\u0026hellip;😅😅\n기분탓일지도 모른다.\n","date":"June 26, 2021","hero":"/posts/cloud/gcp/k8sgke-pod/images/CKA_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/cloud/gcp/k8sgke-pod/","summary":"\u003cp\u003eGKE를 생성해서 kubectl에 익숙해져보자.\u003c/p\u003e","tags":null,"title":"k8s(GKE-Pod)"},{"categories":null,"contents":"GKE를 생성해서 kubectl에 익숙해져보자.\nGCP volume GCP에서의 볼륨 옵션은 그들의 네트워킹 구조와 마찬가지로 zonal, Regional을 선택할 수 있다. 오늘 해볼 것은 Regional SSD Persistent Disk를 생성하여 각 영역에 있는 K8s 노드에 붙여볼 예정이다.\n리소스 생성","date":"June 26, 2021","hero":"/posts/cloud/gcp/k8sgke-volume/images/CKA_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/cloud/gcp/k8sgke-volume/","summary":"\u003cp\u003eGKE를 생성해서 kubectl에 익숙해져보자.\u003c/p\u003e","tags":null,"title":"k8s(GKE-volume)"},{"categories":null,"contents":"GCP Network 서비스 중 CLB와 Instance_group에 대해 빠르게 훑어봤습니다.\n배경 Load Balancing (이하 LB)는 Client로부터 들어오는 트래픽을 여러 Backend Server (Instance, VM)에 분산하는 기능을 가지고 있습니다. 이를 통해 트래픽에 의해 Backend Server의 리소스가 과다하게 점유되어 서버가 터지는 것을 방지하고자 트래픽 즉 부하들을 분산시켜 서비스의 고가용성을 얻음과 동시에 성능적인 이점을 가져갈 수 있습니다.\nLB를 사용한다고 항상 이로움만 얻을 수 있는 것은 아닙니다.\n백엔드 서비스가 빵빵해도 LB 즉 프론트 단의 QPS의 한계로 인해 client의 request를 Drop시키는 경우도 있기 때문입니다.\nLB에서 SSL offloading을 통한 백엔드 서비스의 부하를 줄일 수 있는거고 반대로 L4의 부하를 줄이기 위해 백엔드에서 SSL handshaking을 할 수 있는 것처럼 주어진 상황에 맞게 구성하는 것이 중요합니다.\nAWS에서 Elastic Load Balancing로 서비스되는 것처럼 GCP의 로드밸런서는 CLB(CloudLoadBalancer)로 서비스합니다.\nGCP에서 서비스하는 LB의 특징들을 요약해봤습니다.\n우선 CLB의 서비스적인 특징에 대해 확인해보겠습니다.\nCLB의 특징  프런트엔드 역할을 하는 단일 anycast IP address AWS의 ELB를 사용하던 유저들은 다소 생소할 수 있습니다. 왜냐면 AWS ELB는 FQDN을 통해 ELB를 제공하기 때문입니다.  이는 AWS ELB의 Node라는 개념에 의해 어쩔 수 없이 Endpoint로 FQDN을 제공할 수 밖에 없는 AWS의 특징입니다. 그러나 GCP CLB는 트래픽을 IP를 통해 받을 수 있도록 프런트엔드에 external IP를 부여할 수 있습니다.\n  **백엔드의 자동 지능형 자동 확장 **\n  LB는 SDN 형태로 Software 적으로 만들어진 것이며, 기존의 물리적인 장비가 갖고 있던 하드웨어적 처리 성능 한계를 갖지는 않습니다.\n  SDN의 특성 상, 개념적인 하나의 LB가 하나의 Software Process를 의미하지 않으며, 필요에 따라 (백엔드 구성에 맞물려) 실제의 Data Plane을 담당하는 구성요소는 수평 확장되는 구조입니다.\n  위의 특성들에 의해 전반적으로 성능의 한계는 Backend Services의 규모/구성에 의해 결정되는 요소가 오히려 더 크다고 볼 수 있습니다.\n  병목현상이 일어난다면 AWS는 node에 대한 이슈까지도 염두해두지만 GCP에서는 QPS에 대한 측정 자료나 Backend latency, Total latency 등의 값을 참고하는 것이 이슈를 해소하기 좋습니다.\n    단일 리전에서 애플리케이션을 사용할 때의 리전 부하 분산\n  전 세계에서 애플리케이션을 사용할 때의 전역 부하 분산 (Premium 등급의 Network Tier가 필요)\n  CLB 백단에 있는 모든 백엔드가 auto scaling되진 않습니다. 인스턴스 그룹이 관리형(Managed)인지 비관리형(unManaged)인지에 따라 다르게 동작하며 이 부분은 인스터스 그룹에 대한 이해가 필요합니다.\n  캐시된 콘텐츠 전달을 위한 Cloud CDN과의 통합\n   기본적으로 5-tuple hash 기반의 부하분산을 지원하지만, Statefull한 애플리케이션을 구성했을 경우를 대비하여 세션 어피니티를 지원합니다. 세션 어피니티는 백엔드가 정상이고 용량이 있는 한 동일한 클라이언트의 모든 요청을 동일한 백엔드로 전송합니다.   Cloud Load Balancer 기초 크게 백엔드 서비스, 호스트 및 경로규칙(HTTP/s), 프런트 엔드로 나뉘며 각기 항목별 세부적인 항목들이 있습니다.\nBackend  백엔드 유형 / backend port / 인스턴스 그룹 / 밸런싱 모드 / A capacity scaler / 타임아웃 / 세션어피니티 / 헬스체크 (포트 or 경로)  호스트 및 경로 규칙 (HTTP/s)  호스트 / 경로 / 백엔드  FrontEnd  프로토콜 / 네트워크 계층 / external IP / Front Port  CLB의 종류 - HTTP/HTTPS Load Balancing - TCP/UDP Load Balancing - TCP/SSL Proxy Load balancing CLB는 어느 프로토콜을 지원하는지에 따라 3가지의 종류로 나뉘어집니다.\nHTTP(S), TCP, TCP proxy LB의 차이를 확인해야 헷갈리지 않습니다.\nHTTP/HTTPS Load Balancing  7계층에서 동작합니다. 여러가지 백엔드 유형을 지원하며, 대상 HTTP(S) 프록시는 클라이언트로부터 요청을 받습니다. HTTP(S) 프록시는 트래픽 라우팅을 결정하기 위해 URL 맵을 사용하여 요청을 판단(컨텐츠 기반 부하분산)합니다. 프록시는 SSL 인증서를 사용하여 통신을 인증할 수도 있습니다. 세션 유지 시간은 600초로 고정되어있습니다.  (websocket에는 적용되지않지만, 일반적으로 백엔드가 조기에 세션을 끊는 일이 발생하지 않도록 600초보다 길게 KeepAliveTime Out값을 설정하는 것이 좋습니다.)\n websocket을 지원합니다. gPRC를 지원합니다. (AWS ALB에도 2020년 11월 추가됐습니다.) QUIC를 지원합니다 . (Quick UDP Internet Connections / HTTP3 )  TCP/UDP proxy Load Balancing  4 계층에서 동작합니다. TCP 연결을 통해 들어오는 트래픽이 부하 분산 레이어에서 종료된 후 TCP 또는 SSL을 통해 사용 가능한 가장 가까운 백엔드로 전달됩니다. 자동으로 트래픽을 사용자와 가장 가까운 백엔드로 라우팅합니다. TCP 80 or 8080 Port를 지원하지 않습니다. (HTTP/s LB로 쓰면됩니다.) TCP 프록시 부하 분산기는 역방향 프록시 부하 분산기입니다. 부하 분산기는 수신 연결을 종료한 후 부하 분산기에서 백엔드로 새 연결을 엽니다. 역방향 프록시 기능은 Google 프런트엔드(GFE)에서 제공합니다. 가장 많이 사용되는 TCP 포트 지원: 25, 43, 110, 143, 195, 443, 465, 587, 700, 993, 995, 1883, 3389, 5222, 5432, 5671, 5672, 5900, 5901, 6379, 8085, 8099, 9092, 9200, 9300.  TCP/UDP Load Balancing  4 계층에서 동작합니다. pass-through LB 입니다. (글로벌 서비스를 위해 백엔드에서 모든 Ingress IP/port에 대한 허용이 필요합니다. ) 수신(ingress)/요청(request) 패킷만 lb를 통과 - 송신(engress)/응답(response) 패킷은 lb를 거치지 않고 바로 client로 가는 DSR로 동작합니다.  부하 분산된 패킷은 소스 IP가 변경되지 않은 백엔드 VM에서 수신됩니다. 부하 분산된 연결은 백엔드 VM에 의해 종료됩니다. 백엔드 VM의 응답은 부하 분산기를 통하지 않고 클라이언트에 직접 전달됩니다. (위에서 설명한 DSR이 이것입니다.)   연결 추적 테이블과 구성 가능한 일관된 해싱 알고리즘을 사용하여 트래픽이 백엔드 VM에 분산되는 방식을 결정합니다. Proxy가 아닙니다. 그렇기에 모든 트래픽은 proxy가 아닌 LB를 통해 전달되며 동일한 지역의 VM 인스턴스 간에만 트래픽을 분산합니다. 앞서 HTTP/s, TCP/UDP proxy LB들과 같은 Regional LB와는 달리 전달 규칙을 사용하여 수신 IP 프로토콜 데이터를 기반으로 시스템의 부하를 분산합니다. 백엔드 VM이 비정상 상태여도 TCP 패킷에 응답하면 세션을 다른 백엔드 VM으로 넘기지 않습니다.  이 LB를 선택하는 이유는 TCP/UDP proxy LB에서 지원하지 않는 포트에서 부하분산을 구성할 때 사용합니다.\nSSL offloading 당연하게도..SSL Offloading을 지원합니다.\nAWS에서는 ACM 에서 발급이 가능했다면 GCP 또한 google Managed SSL 인증서를 지원합니다.\nGoogle 관리형 SSL 인증서는 도메인에서 Google Cloud가 가져오고 관리하는 도메인 유효성 검사(DV) 인증서입니다. 각 인증서에서 여러 호스트 이름을 지원하며 Google은 인증서를 자동으로 갱신합니다.\n이를 통해 External HTTPs LB, SSL proxy LB를 구성할 수 있습니다.\n사용하면서 배운 것들 1. LB를 사용할 때 백엔드 서비스 구성 우선 LB의 백엔드 구성 간 선택지는 기본적으로 백엔드 서비스, 버킷, TCP에는 인스턴스 Pool을 직접 연결하기도 하지만 저의 경우 GCP 내의 VM으로 트래픽을 전달받아야하기 때문에 백엔드 서비스의 인스턴스 그룹 혹은 인스턴스 Pool로 셋팅합니다.\n이때 그룹의 종류가 두가지로 나뉘는데 앞서 1편에서 말했던 인스턴스 그룹의 두 종류인 비관리형(Unmanaged Instance Group)과 관리형(Managed Instance Group) 그룹입니다.\n1-1 MIG는 단일 region 내 멀티 zone에 VM 인스턴스를 분산함으로써 single zone failure 에 대응하여 워크로드의 고가용성을 높일 수 있습니다.\n예를 들어, zonal failure 가 발생하거나 특정 zone 내에 위치한 인스턴스들에 장애 발생시, regional MIG 에 포함된 다른 zone에서 실행되는 인스턴스가 트래픽을 처리함으로써 고가용성을 구성할 수 있습니다.\n[MIG 의 특징]\n  애플리케이션 로드를 멀티 zone 으로 분산\n  최대 2,000개의 인스턴스까지 관리 가능 (zonal MIG의 2배)\n  멀티 zone 을 사용함으로써 zonal failure 및 단일 zone 내 인스턴스 그룹의 오작동과 같은 시나리오로부터 보호\n  zonal failure 발생 혹은 zone 내 인스턴스 장애시, regional MIG에 포함된 다른 zone 에서 트래픽을 처리\n  1-2 UIG는 단순히 같은 zone내의 인스턴스들을 집합화 시킨 server pool이라고 이해하면 됩니다.\n인스턴스 템플릿이 필요하지 않습니다. 단지 같은 zone내의 인스턴스라면 그룹화시켜 LB를 통해 트래픽을 받을 수 있습니다.\nUIG를 사용할지 MIG를 사용할지는 어떤 서비스를 제공하는지에 따라 다릅니다. [저희팀에서는 UIG로 인프라를 구성하고 관리합니다.]\nMIG는 동일한 구성의 인스턴스를 여러 개 만들기 위한 것입니다. 기존 인스턴스 템플릿을 업데이트하거나 생성된 인스턴스 템플릿을 변경할 수 없습니다. 구성을 변경해야 하는 경우 새 인스턴스 템플릿을 만들고 새로운 UIG를 생성해야합니다. (혹은 롤링업데이트..) 매번의 변경사항이 있을때마다, 이미지를 새로 생성하고 템플릿으로 만들어서 배포에 추가하기엔 대응이 너무 늦습니다. 또한 스펙까지 고정되어야 합니다..\n그러나 UIG는 전혀다른 스펙과 구성의 인스턴스들을 그룹핑 시킬 수 있습니다.\n따라서 서비스의 특성 상 순간적인 트래픽이 발생하기보단 꾸준한 유저들의 동접 수를 대응하기에 예상 트래픽의 최대치를 기준으로 서버를 생성하고 일정기간 모니터링하여 optimizing하는 방법으로 GCP를 활용하고 있습니다.\n2. Global HealthCheck AWS를 사용할때는 ALB의 sg를 참조하여 백엔드 EC2의 보안그룹을 유연하게 구성했다면, 다행히 GCP LB에서는 LB에 node 개념이 없습니다.\n다만, Global HC라고하는 백엔드에 연결하는 전역 및 리전별 상태 확인 시스템을 제공합니다.\n Global Healthcheck가 존재합니다. (백엔드 서비스의 방화벽에서 필수적으로 Ingress를 허용해줘야 합니다. )  각 연결 시도를 프로브라고 부르고, 각 상태 확인 시스템을 프로버라고 부릅니다.\n3. 인스턴스와 인스턴스 그룹 재사용 하나의 인스턴스는 동시에 여러 인스턴스 그룹에 그룹핑될수 없습니다.\n만약 한대의 인스턴스 내에 여러 서비스가 올라가있는 상태라면 Instance Group으로 나눌수는 없으니 백엔드 포트를 서비스 마다 열어두고,\n한대의 인스턴스 그룹을 여러 LB로 연결하는 방식으로 재사용 해야합니다.\n4. 결론 결론적으로 CLB는 유저의 Ingress/Request에 대한 트래픽을 어떤 프로토콜을 통해 받아서 어떤 방식으로 백엔드에 전달하는가에 따라 종류가 나뉘어지며\n크게는 OSI 7 Layer에 의해 (HTTP, TCP/UDP)로 나뉘며, Traffic Flow 자체는 Front 단에서의 전송방식 및 Egress/Response를 기준으로 구별합니다. (Proxy의 유무)\nHTTP/s or TCP (Proxy) LB의 경우\n IPv4, IPv6 프로토콜을 모두 지원하며, 전달 규칙(Forwarding rule)을 HTTPS proxy에서 URL map을 통해 각 백엔드 서비스로 프록시 처리됩니다. 네트워크 등급에 따라 Global, Regional LB의 지원 여부가 달라집니다. 기본적으로 균등하게 부하를 분산하지만, 아주 작은 수의 요청은 균등하게 분배되지 않을 수 있습니다 Session affinity를 통해 해시를 기반으로 특정 클라이언트의 요청을 동일 백앤드 VM으로 전달하도록 설정 할 수 있습니다. SSL offloading을 지원합니다.  GCP에서 제공하는 LB 선택 로드맵입니다.\nLoadbalancing Test 부하분산이 정상적으로 이뤄지고 있는지 확인해봅시다.\n목차 [1. HTTP/s LB 테스트] [2. TCP LB 테스트] [3.TCP porxy LB 테스트]  인스턴스 그룹 생성 기본적으로 백엔드 서비스는 UIG로 생성할 예정이며 단일 존 내부에 두대의 Web service를 띄워 확인해보겠습니다.\n상태 검사 생성 우선 Http-80으로 상태 검사를 진행할 예정입니다. 고고\nHTTP/s LB-Test LB 생성 HTTP Backend 생성 HTTP 검토 및 확인 나머지 LB들도 동일하게 구성하면 되기에 configuration에 대한 내용은 여기까지\u0026hellip;! Test 를 하러갑시다.\n(TCP LB는 그룹이 아닌 인스턴스 Pool로 등록 / TCP LB생성 간 단일리전으로 선택하면 TCP proxy가 아닌 TCP LB로 구성을 도와줍니다.)\nTest 1. Health check 확인 LB를 생성하고 나면 정상상태의 인스턴스가 확인되지 않는다. 당연히 80포트의 데몬이 떠있질 않으니, 헬스체크가 안되는겁니다.\n우선 인스턴스 방화벽에서 35.191.0.0/16,130.211.0.0/22 80 Ingress를 허용해준 뒤, 얼른 서버로 접근하여 httpd를 띄워봅시다~\n http 데몬을 올린 뒤, 설정해둔 상태검사 포인트만큼 수십초를 기다리면 금방 헬스체크가 되는 모습을 볼 수 있습니다. F5를 다다다닷 누르기는 싫어서 curl을 실행하는 간단한 스크립트를 통해 확인해본 결과,\n#!/bin/bash number=0 while [ $number -le 50 ] do curl 34.98.79.168 \u0026gt;\u0026gt; $(date +\u0026quot;%y%m%d\u0026quot;).txt sleep 3 ((number++)) done Web 1번 22회, Web 2 29회가 확인됩니다. 왜 정확히 반반 나뉘지 않는걸까요?\n-# GCP의 설명 #-\n\u0026quot;- 기본적으로 균등하게 부하를 분산하지만, 아주 작은 수의 요청은 균등하게 분배되지 않을 수 있습니다\u0026quot;\n\u0026hellip;흠..🤣🤣🤣🤣🤣🤣\nAccess log 확인 그럼 실제 서버에서는 어떻게 요청이 오는지 Access.log를 통해 확인해보겠습니다.\nHC 대역인 35.191.0.0/16으로 Healthcheck와 Client의 요청과 결과가 잘 찍혀있네요.\n왜 HC 대역이 access log에 남는걸까요?\n실제 부하 분산 트래픽의 소스 IP 주소는 상태 확인 프로브 IP 범위와 같기 때문입니다.\n부하 분산기는 수신 연결을 종료한 후 부하 분산기에서 백엔드로 새 연결을 엽니다.\n이후 target proxy에서 URL map을 통해 백엔드 서비스쪽으로 reverse proxy하기에 백엔드 서비스는 실제 Source IP를 알 수 없는겁니다.\nSource IP가 필요하다면 X-forward-for Header를 통해 확인 할 수 있습니다.\nHTTP backend session affinity 생성해놨던 HTTP LB의 백엔드 구성에서 cookie를 생성해줍니다. 생성된 쿠키 어피니티가 설정되면 LB가 첫 번째 요청에서 쿠키를 생성합니다.\nLB는 동일한 쿠키를 사용하는 각 후속 요청에서 같은 백엔드 VM 또는 엔드포인트로 요청을 전달합니다.\nGCLB라는 cookie가 확인됩니다. 쿠키 값을 통해 고정 세션을 유지할 수 있습니다. 영원히 세션이 고정되는것은 아닙니다.\nTimeout으로 설정해둔 (HTTP는 Keep AliveTimeout값이 제한 시간 값을 따라갑니다.) 30초 후엔 새로운 세션이 연결됩니다.\n위 결과, (31초 후 curl -i 동작) 31초마다 세션이 바뀌는걸 확인할 수 있습니다.\n","date":"June 25, 2021","hero":"/posts/cloud/gcp/gcp-clb/images/thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/cloud/gcp/gcp-clb/","summary":"\u003cp\u003eGCP Network 서비스 중 CLB와 Instance_group에 대해 빠르게 훑어봤습니다.\u003c/p\u003e","tags":null,"title":"GCP CLB, Instnace_group"},{"categories":null,"contents":"제목은 GCP VPC에 대해서 메모라고 하겠습니다. 이제 약간 AWS VPC를 곁들인..\n배경 GCP를 통해 클라우드를 입문하셨거나, AWS를 사용하다가 GCP로 넘어오신 분들, 갑작스런 변화에 살짝 오잉? 하셨을겁니다.\n저는 저만의 오잉 포인트들을 모아서 기록해두었습니다. 고고\nGCP의 VPC (Virtual private cloud) GCP의 VPC에 대해 우선 짚어봅시다.\nVPC (Virtual private cloud)란, 간단하게 클라우드 환경 상의 논리적으로 격리된 개개인의 사설 네트워크 망을 말합니다.\n보통 AWS의 인프라 환경은 굉장히 계층적인 구조를 보여줍니다.\n가령, 리전(국가) 내에 여러 가용영역(도시)들이 있으며 가용영역들은 1개이상의 개별 데이터센터로 구축되어있습니다.\n또한 가용영역 간 동기복제를 수행하기 떄문에 사용자는 여러 리전, 가용영역들에 애플리케이션을 배포함으로써 고가용성의 이점을 얻을 수 있습니다.\n들어가기 앞서 기본적으로 AWS GCP의 공통사항을 먼저 다루자면\n서브넷에 이미 AWS(GCP)에서 예약해놓은 IP 주소들이 있다는 점 참고해주세요.\nx.x.x.0 / x.x.x.1 / x.x.x.254 / x.x.x.255\n 구조적 차이 AWS는 말그대로 계층적인 구조를 가지고 있습니다.\n Virtual Private Cloud(VPC) — 사용자의 AWS 계정 전용 가상 네트워크입니다. 서브넷 — VPC의 IP 주소 범위입니다. 라우팅 테이블 — 네트워크 트래픽을 전달할 위치를 결정하는 데 사용하는 라우팅이라는 이름의 규칙 집합입니다. 인터넷 게이트웨이 — VPC의 리소스와 인터넷 간의 통신을 활성화하기 위해 VPC에 연결하는 게이트웨이입니다.  VPC는 리전에 연결되어 Cidr값을 지정하고 Cidr값을 subnetting하여 각 가용영역에 지정합니다.(인스턴스를 생성해야하니까요!?)\nGCP는 다릅니다. 애초부터 VPC가 리전에 종속되지 않습니다.\nGCP의 VCP는 특정 가용영역과 리전에 종속되지 않는 전역 리소스입니다. GCP에서의 전역리소스는 동일 프로젝트 내의 모든 영역에 있는 모든 리소스가 엑세스 할 수 있다는 뜻입니다.\n Virtual Private Cloud(VPC) — 사용자의 GCP 계정 전용 가상 네트워크입니다. 서브넷 — VPC의 IP 주소 범위입니다. 아닙니다. 각 가용영역 (GCP에선 zone)의 대역입니다. 라우팅 테이블 — 네트워크 트래픽을 전달할 위치를 결정하는 데 사용하는 라우팅이라는 이름의 규칙 집합입니다. 인터넷 게이트웨이 — VPC의 리소스와 인터넷 간의 통신을 활성화하기 위해 VPC에 연결하는 게이트웨이입니다.  AWS에서 도쿄리전과 서울리전의 각각의 인스턴스를 두고 있고 서로 통신이 필요할 경우, 별도의 분리된 VPC 간의 통신을 지원할 무언가가 필요한 상황입니다.\n그러나, GCP의 서브넷이 리전에 연결되기에 단지 내부 라우팅을 열어줌으로써 도쿄 리전의 인스턴스와 서울리전의 인스턴스가 통신이 가능하게 된다는 말입니다.\nVPC는 리전에 종속되지 않습니다. VPC 내 서브넷들이 각 리전에 연결되어 Cidr값을 지정하고 Routing Table, Firewall rule에 따라 트래픽의 흐름을 보여줍니다.\nVM의 중단없이 Subnet의 확장이 가능합니다.\n차이를 하나만 더보자면 아마 피어링 ? (VPC Peering) 각 벤더에서 VPC 간 트래픽을 라우팅 하고자할때 위와같은 특성에 의해 고려해야될 부분들이 있습니다.\nAWS는 이래요 동일 리전의 VPC 간 peering, 계정 간 VPC peering, 리전간 VPC peering으로 나뉩니다.\n이때 3가지 방법 모두 라우팅 테이블에 peering connect를 만들어 서로 본인의 사설 Cidr 값을 라우팅으로 추가해주어야 합니다.\nGCP는 서로다른 Organization, project 간 VPC 피어링만 고민하면된다. 리전 간 통신은 위 설명대로 방화벽으로 제어하며, 방화벽 상에서 서로의 서브넷을 ingress, Egress로 추가한 네트워크 태그를 인스턴스에 추가하여 허용할 수 있기 때문에 서로 다른 Org 간 혹은 Project 간의 Priavte 통신이 필요한 경우에만 고려하면 됩니다.\nVPC peering을 고려한다면 AWS든 GCP든 subnet을 겹치게 생성하지 말자. 중요합니다. 만약 AWS든 GCP든 VPC를 분리하여 사용하고자 할 때 (가령 중앙화나 로그수집에 대한 인프라 구축, VPN 등) 서브넷의 대역이 겹쳐 피어링을 맺지 못한다면 Public IP 간 통신을 해야합니다. 트래픽이 Global 망을 타고 나갔다 들어오기 떄문에 보안적으로도 비용적으로도 성능적으로도 좋지 못한 구성이기 때문입니다.\n대역이 겹치는 이슈 이외에도 몇가지 제한되는 사항들이 있는데, 이는 각 벤더 문서에서 VPC peering을 검색해보면 됩니다. 가령 미리 예약해둔 4개의 IP (Brodcast IP)등 일반적으로 예약되는 RFC 범위에 대해 제한사항이 있습니다. 아래는 공통적으로 제한되는 부분에 대해서만 서술해두었습니다.\n제한사항   피어링된 한 VPC 네트워크의 서브넷 CIDR 범위는 다른 피어링된 네트워크의 대역과 겹칠 수 없습니다.\n 제.곧.내 (제목이 곧 내용)    직접 피어링된 VPC끼리만 통신이 가능합니다.\n  가령 A, B, C VPC가 있다고 가정하였을때, A \u0026lt;-\u0026gt; B 사이에 peering을 구성해놓고, 이후 B\u0026lt;-\u0026gt;C의 피어링을 맺으면 중간의 B VPC가 마치 Hub의 역할을 하여 A\u0026lt;-\u0026gt;C도 connection이 이뤄진다고 생각할 수 있습니다.\n결론부터 말하자면 불가능합니다.\nVPC peering의 connection은 각각 독립적인 Connection이기에 위와같은 구조를 원한다면 AWS Trangit Gateway를 통하거나, 처음부터 B\u0026lt;-\u0026gt;C의 peering을 설정하면 되는 문제입니다.\n    제한사항은 아니지만 보통 피어링이 성공적으로 Connection이 이뤄졌는데도 불구하고, 서버 간 통신이 안되면 라우팅경로와 서버의 보안그룹(방화벽)등을 확인해야 합니다.\n  GCP VPC와 나아가 Network Peering에 대해 간단하게 풀어봤습니다.\n추후에는 VPC flow logging과 일명 \u0026ldquo;고급 VPC\u0026quot;에 대해 메모해놓을 예정입니다.\n감사합니다.\n","date":"June 24, 2021","hero":"/posts/cloud/gcp/gcp-vpc/images/gcp_vpc.jpg","permalink":"https://hugo-toha.github.io/posts/cloud/gcp/gcp-vpc/","summary":"\u003cp\u003e제목은 GCP VPC에 대해서 메모라고 하겠습니다. 이제 약간 AWS VPC를 곁들인..\u003c/p\u003e","tags":null,"title":"Google Cloud Network 기초"},{"categories":null,"contents":"GCP에서 발생하는 host error 외 이상한 경험에 대해 간략하게 적어두었습니다.\n배경 지난번 AWS이슈에 이어 GCP에서의 이슈에 대해 정리해보았습니다.\n우선 Host error에 대해 GCP의 Compute Engine은 소프트웨어 또는 하드웨어 업데이트와 같은 호스트 시스템 이벤트가 발생하더라도 가상 머신 인스턴스가 계속 실행될 수 있게 해주는 라이브 마이그레이션 기능을 제공합니다.\nCompute Engine은 사용자가 VM을 재부팅할 필요 없이 동일 영역에서 실행 중인 인스턴스를 또 다른 호스트로 라이브 마이그레이션합니다.\n이렇게 해서 Google은 사용자의 VM에 영향을 주지 않으면서도 인프라를 보호하고 안정적인 상태로 유지하는 데 반드시 필요한 유지보수를 수행할 수 있습니다. (GPU가 연결된 인스턴스는 불가능하다는 점 !)\nGCP도 역시 Host Error가 발생합니다. 자동으로 올라오지만, 마찬가지로 모니터링 및 트리거를 걸어 Reboot try 로직을 걸어두심이 좋습니다.\n다시한번 말하지만 세상에 100% 안죽는 서버는 없습니다. (사장님 이젠 죽을거 같습니다)\n그렇게 때문에 항상 DR 프로세스에 대한 준비는 해두어야합니다. 이것은 클라우드 위의 인프라도 마찬가지 입니다.\n클라우드는 공동 책임 모델 등 SLA를 명확하게 보여주기에 어느정도의 가용성을 보장하는지가 알려줍니다.\n가령 99.999%를 보장하는 서비스는 최소 1년에 0.001%의 보장할 수 없는 서비스 중단시간이 발생할 수 있다는 소리입니다.\n31536초면 약 9시간쯤 되겠네요.\n역시나 운영비를 늘려 서버를 고가용성으로 구성하는것이 가장 바람직하지만 백업과 모니터링에 집중하여 일정부분 타협이 가능할 것 같습니다.\n실제로 이런 일이 있습니다. (가용영역의 리소스 부족) GCP, AWS를 막론하고 내가 원하는 가용영역에 리소스가 부족하는 경우가 있습니다. 이때 서버 생성이 불가함은 물론이거니와, 이미 있던 내 서버들이 갑작스레 Host error등으로 죽었는데, host hardware의 리소스가 부족해서 VM migration이 발생하지 않으면 어떻게 될까요? 어떻게 되긴 뭘 어떻게 됩니까. 큰일났지 !!!__!_!😫😫😫\n해결 방안 -1 (zone을 바꿔보자) 쉽게 생각하면 그렇습니다. VM들을 다른 가용 가능한 zone으로 이동시키면 됩니다.\nAWS에서는 스냅샷 혹은 AMI를 통해 인스턴스를 재 구성하였다면 GCP에서는 GCP CLI에서 영역 간 인스턴스 이동을 지원합니다. 옮기는 동안 서버에서 생성한 인스턴스와 디스크의 일부 속성이 변경됩니다.\n변경되는 속성\n이 방법으로 이관하지 못한 이유가 있습니다.\n 비관리형 인스턴스 그룹를 타겟으로한 LB를 운영하고 있습니다.  - 비관리형 인스턴스 그룹은 영역끼리 그루핑해야하기에 같은 그룹의 인스턴스를 전부 이관해야합니다. 그렇다고 관리형 인스턴스 그룹은 되느냐? 그것도 아닙니다. 관리형 인스턴스 그룹의 구성일 경우 서브넷 변경까지 필요합니다.  UEFI 기반 VM는 위 CLI를 통해 자동으로 존 변경이 불가합니다.  - 수동으로 진행하면 됩니다. 대략적인 작업 흐름은 아래와 같습니다. (수동, 자동 동일) 1. 원본 인스턴스에 연결된 영구 디스크의 스냅샷을 만듭니다. 2. 대상 영역에 영구 디스크의 사본을 만듭니다. 3. 외부 및 내부 IP 주소: 동일한 리전 내의 영역 간에 인스턴스를 이동하고 임시 IP 주소를 보존하려면 인스턴스에 할당된 임시 IP 주소를 고정 IP 주소로 임시 승격한 다음 대상 영역에 만든 새 VM 인스턴스에 할당합니다. 인스턴스를 리전 간에 이동하는 경우에는 VM 인스턴스의 다른 IP 주소를 선택해야 합니다. 4. 대상 영역에 새 인스턴스를 만들고 부팅합니다. 서로 다른 리전 간에 이동하는 경우에는 새로운 인스턴스의 새로운 서브네트워크도 선택해야 합니다. 5. 새로운 영구 디스크를 새로운 인스턴스에 연결합니다. 6. 새 인스턴스에 외부 IP 주소를 할당합니다. 필요한 경우 주소의 수준을 다시 임시 외부 IP 주소로 낮춥니다. 7. 스냅샷, 원본 디스크, 원본 인스턴스를 삭제합니다.  두개 이상의 볼륨을 마운트 하고 있습니다.  결론적으로 우리는 비관리형 인스턴스 그룹으로 그룹핑해놓은 두개이상의 볼륨이 마운트된 UEFI 기반의 VM 구성이기에 CLI를 통해 이관은 불가했습니다. 또한 당장 해당 리전을 사용하는 vm의 갯수가 수 백대는 되기에 현실적으로 어려움이 있습니다.\n해결 방안 -2 (타입을 바꿔보자) 그래서 이 방법을 택했습니다. 모든 인스턴스에 기본적으로 인스턴스 reboot이나 host error 발생 시, 알람을 걸어두었습니다. 혹시라도 Host error 이후 정상화가 되지 않는 특정 존의 인스턴스 경우 이벤트로그를 통해 원인을 확인하고 만약 리소스 부족이 원인이라면 해당 존에서 가용할 수 있는 타입으로 인스턴스를 변경하는 것으로 처리하는 것이지요.\n결론 그래서 결론이 없는 문제입니다. 사고를 미연에 방지하고자한다면 해당 리전/가용영역에 미리 리소스를 선점해두는 방법밖에 없을 것 같습니다.\n","date":"June 23, 2021","hero":"/posts/cloud/gcp/gcpissue-1/images/host_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/cloud/gcp/gcpissue-1/","summary":"\u003cp\u003eGCP에서 발생하는 host error 외 이상한 경험에 대해 간략하게 적어두었습니다.\u003c/p\u003e","tags":null,"title":"서버가 갑자기 박살나셨습니다. -GCP"},{"categories":null,"contents":"AWS EC2 Maintenance에 대해 적어뒀습니다.\n배경 GCP 혹은 AWS를 사용하면 심심치않게 일어나는 서비스이슈, 1년에 한 두번 일어날까말까하는 리전이슈가 있습니다. 서비스마다 대응방법이 다르지만, 우선 가장 비번하게 일어나는 Host hardware 이슈에 대해 기록합니다.\n종종 Host Error! 혹은 Instance check Failed를 경험한 적이 있으실겁니다.\n 출처 : AWSKRUG slack채널  AWS System Check failed 다들 아시다시피 ec2 인스턴스는 AWS에서 Iaas 방식으로 제공하는 서비스이기에 사용자가 해당 ec2 인스턴스를 프로비저닝하게 될 경우 선택한 리전과 가용영역의 데이터 센터 내 host computer에서 hypervisor 위에 고객의 요청에 의해 insatnce를 생성하여 제공하는 방식입니다.\n여기서 만약 hypervisor와 instance간의 Network이 끊긴다면..? 아니면 Host 장비에 불이 난다면\u0026hellip;?\n와장창-! 말 그대로 인스턴스가 와장창 납니다.\n이러한 갑작스러운 이슈로 인해 발생하는 AWS 하드웨어의 Maintenance Event 혹은 System checkfailed 이슈로 인해 발생하는 예기치않은 이슈에 대해 정리하고 사례에 맞춰 사용자들은 어떻게 대처해야하는지에 경험을 공유하고자 합니다.\nAWS Maintenance 우선 AWS에서의 EC2 Event 종류와 Cloudwatch에서 확인할 수 있는 Status Check failed 지표는 아래와 같은 내용을 포함합니다.\n  AWS Event\n Instance stop : 예약된 시간에 인스턴스가 중지됩니다. 인스턴스를 다시 시작하면 새 호스트로 마이그레이션됩니다.  이러한 유형은 Amazon EBS가 지원하는 인스턴스에만 적용됩니다.\n Instance retirement Instance reboot System reboot System maintenance    Instance stop : 예약된 시간에 인스턴스가 중지됩니다. 인스턴스를 다시 시작하면 새 호스트로 마이그레이션됩니다.\nInstance stop이 일어나는 경우는 대게 Host hardware의 폐기 날이 결정된 것입니다.\n이 경우, Maintenance 일정 이전에 스스로 stop/start를 진행하여 해소 할 수 있습니다.\n두 눈을 크게 뜨고 정확히 봐야합니다. Instance reboot이 아닌, Stop인 것을요.\nStop되어있는 인스턴스는 어떤 트리거가 발생하기 전까지는 결코 혼자서 벌떡 일어나진 않습니다.\n이러한 유형은 Amazon EBS가 지원하는 인스턴스에만 적용됩니다.  참고로 PHD(persnal Health Dashborad)에서 성능저하로 인해 예약된 이벤트들의 경우 되도록 빨리 인스턴스를 재부팅하여 새 호스트로 마이그레이션하는 것이 좋습니다.\n이미 성능이 저하된 호스트 하드웨어이기에 언제 어떤이슈가 발생할지 모르는 폭탄이기 때문입니다.\nInstance retirement : 예약된 시간에 인스턴스가 Amazon EBS에서 지원되는 경우 중지되거나 인스턴스 스토어에서 지원되는 경우 종료됩니다.\n말 그대로 EBS 지원 인스턴스는 stop, 인스턴스스토어 지원 인스턴스는 terminate되는 이벤트입니다.\n아직 발생해본적이 없어서 패스하겠습니다. (뭐..다를거 있겠냐만..)\nSystem Maintenance : 예약된 시간에 네트워크 또는 전력 유지 관리로 인스턴스가 일시적인 영향을 받을 수 있습니다\n네트워크 유지 관리 시에는 예약된 인스턴스의 네트워크 연결이 잠시 동안 끊어집니다. 유지 관리가 완료되면 인스턴스의 네트워크 연결이 평소처럼 복구됩니다.\n전력 유지 관리 시에는 예약된 인스턴스가 잠시 동안 오프라인 상태로 전환되었다가 재부팅됩니다. 재부팅 이후에도 인스턴스의 모든 구성 설정은 그대로 유지됩니다.\n이제 가장 주로 겪은 두가지 이벤트를 다뤄보겠습니다.\n하이라이트 입니다.\nInstance reboot : 예약된 시간에 인스턴스가 재부팅됩니다.\n말그대로 인스턴스의 재부팅을 의미하기에 os에서 reboot하는것과 동일하게 동작합니다.\n메인터넌스 일정 이내에 사용자가 스스로 reboot을 먼저 실행하여 해소하는 방법과 메인터넌스 일정에 자연스럽게 해소하는 방법이 있습니다. EBS 볼륨의 데이터는 영향을 받지 않습니다.\n유의사항으로는 인스턴스 재부팅 시 인스턴스스토어 볼륨 데이터와 public IP가 변경되기에 Elastic IP를 할당하여 고정 IP를 사용하고\n만약 인스턴스스토어 볼륨을 사용한다면 미리 데이터를 백업해놓아야 합니다.\nSystem reboot : 예약된 시간에 인스턴스의 호스트가 재부팅됩니다.\n인스턴스의 재부팅이 아닌, 인스턴스가 올라가있는 호스트 하드웨어의 재부팅입니다.\n일반적인 사용자가 스스로 이벤트를 해소할 수 있는 방법이 없습니다.\nAMI를 생성해서 다시 인스턴스를 구성할 경우 메인터넌스 이벤트를 회피할 수 있습니다. (Instance reboot과 동일하게 Elastic IP 유지필요, 인스턴스스토어 볼륨 데이터 증발)\n필요에 의하지 않다면 AWS에 온전히 작업을 맡기는 것도 좋은 방법입니다. (이 맛에 클라우드 쓰지)\n다행히도 AWS가 시스템을 재부팅해도 DNS 이름이나 IP 주소와 같은 구성이 변경되지 않으며, 로컬 인스턴스 스토어에 저장된 데이터도 그대로 보존됩니다.\n통상 이러한 재부팅들은 수 분 내에 끝난다고 말하지만 대부분의 경우 3분안에 이벤트가 종료되었던 것으로 경험했습니다.\n모든 경우에서 서비스 서버(EC2)들은 AMI나 Snapshot을 통해 백업해두는 것이 가장 현명합니다.\n이제 메인 빌런인 갑작스러운 하드웨어 이슈에 의한 EC2 Reboot 입니다.\n보통 잘자다가 새벽에 천둥같은 알람이 울면 인스턴스의 모니터링 지표에 (System, Instance) Status check failed 알람이 발생하는 경우도 있습니다.\n이게 무엇인고하니, AWS는 두 가지 상태 확인을 통해 각 EC2 인스턴스 상태를 내부 모니터링 툴을 사용하여 모니터링합니다.\n 요약  시스템 상태 확인 실패(System status check failed)는 인스턴스가 실행되는 AWS 시스템에 문제가 있음을 나타냅니다. (하드웨어 이슈) 인스턴스 상태 확인 실패(Instance status check failed)는 대게 OOM(OutOfMemory) 등 리소스 이슈 혹은 잘못된 OS config 수정에 의해 발생합니다. (OS 이슈) ~~(간혹 커널이슈)    그렇기에 만약 인스턴스가 죽어서 Cloudwatch의 메트릭에서 위와같은 상태 검사 메트릭을 우선 확인한 뒤,\nCPU, memory (Custom Metric으로 받아와야합니다.), Volume IO 등 리소스 사용량과 콘솔 상에서 확인할 수 있는 시스템 로그를 통해 dmsg 로그 확인 및 본인이 마지막으로 서버에 무슨 작업을 했는지 확인해야하고 (어쩔때는 갑자기 DHCP서버에서 EC2가 IP를 못받아서 죽었던 경험도 있습니다. Network Manager issue 였죠..)\n3\n시스템 상태검사 실패라면 재빠르게 stop/start 혹은 해당 이벤트를 트리거로 걸어두어 자동 reboot 작업을 걸어두는 것이 좋습니다.\nAWS 인스턴스 상태 모니터링 링크\n결론 세상에 100%의 가용성을 보장하는 서버는 없습니다. 그렇기에 SLA 기준이 존재합니다.\n그러니 어쩔수 없는 상황에 대해서는 어느정도 인정이 필요합니다.\n결국 어떻게 이슈를 대응하여 문제를 최소화하는것에 대해 고민이 필요한 것이지요.\n서버 한 두대가 죽어도 서비스는 유지될 수 있도록 흔히 말하는 고가용성을 보장하는 아키텍쳐가 필요하다고들 합니다.\n그건 어디까지나 AWS나 파트너사의 입장이고 실제 운영하는 입장에선 모든 상황에 고가용성 구성이 성능적이나, 비용적으로 효율적이지 못한 구조일 수 있습니다. 가령 zone간 혹은 리전 간 latency 등.. 실시간으로 트래픽을 처리해야되는 구조가 특히 힘들지요.\n제가 생각하는 논리는 이렇습니다.\n  서버는 갑작스럽게 죽을 수 있다. -\u0026gt; 고가용성 구조가 필요하다 -\u0026gt; 비용적으로 이슈가 있다 -\u0026gt; 모니터링 시스템이 의존도가 높을 수 밖에 없다. (가령 EC2 host issue alret 발생 시, EC2 auto reboot trigger 등)\n  AMI 백업을 주기적으로 실행한다.\n  이미 서버가 죽어서 서비스에 이슈가 발생했을 경우에 가장 필요한건 서비스의 빠른 Recovery이니까요.\n관련해서 나중에 모니터링관련(Promethus, logstash,Fluentd) 내용도 정리하도록 하겠습니다.\n감사합니다.\n","date":"June 22, 2021","hero":"/posts/cloud/aws/awshost_issue/images/host_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/cloud/aws/awshost_issue/","summary":"\u003cp\u003eAWS EC2 Maintenance에 대해 적어뒀습니다.\u003c/p\u003e","tags":null,"title":"서버가 갑자기 박살나셨습니다. -AWS"},{"categories":null,"contents":"컨테이너 Network부터 Pod Network까지 기록해봤습니다.\nDocker Networking  격리된 환경에서 실행되는 하나의 프로세스 위에서 격리된 환경을 구현하는 기술은 chroot, cgroups, namespace  namespace : 네트워크인터페이스, 라우팅, 방화벽 규칙들을 격리한다. 이런 namespace로 인해 격리된 PID들은 veth를 통해 연결한다. veth : linked virtual ethernet device pair = 항상 쌍 (pair)로 생성되어 연결된 상태를 유지한다.    직접 Namespace를 생성해보자.\nlocal namespace와 ipnetns add를 통해 만든 namespace에 veth를 붙여봤다.\n컨테이너를 새로이 배포할때마다 컨테이너에게 veth0라는 가상 네트워크 인터페이스를 할당하여 docker0에 연결, linked virtual ethernet device pair로 컨테이너와 bridge를 연결한다.\n 도커 설치 직후 상태  bridge Network 결국 컨테이너 네트워크 인터페이스 (Namesapce 내 veth)들은 bridge(docker0 : docker 시작시 기본적으로 생성되는 bridge)를 통해 연결되어 하나의 세그먼트로 구성되지만, 같은 bridge에 연결되지 않은 컨테이너들은 격리된 공간을 유지한다.\n[eth0 -\u0026gt; docker0(bridge) -\u0026gt; veth0(host) \u0026lt;-[pairing]-\u0026gt; veth0(container) -\u0026gt; container]\n위 이미지에서 bridge의 subnet과 Gateway를 보고 밑에 container의 IP를 보면 확실하다.\n아니면 brctl show 명령어를 통해 bridge에 연결되어있는 Interface에 veth를 확인하면 된다.\ndefault bridge 말고, custom bridge를 생성하여 별도의 네트워크 구성도 물론 가능하다고 하지만, 해보진 않았으므로 잠시 미뤄두겠다.\nHost Networking Host에서 사용하고 있는 네트워크를 그대로 컨테이너가 사용한다.\n그렇기 떄문에 컨테이너에 IP(veth)를 할당하지 않기에 bridge에 바인딩이 되지 않는다.\noverlay Networking 다른 도커 데몬 host의 container와 통신하기 위해 보통 OS레벨에서의 라우팅이 필요하지만, Overlay 네트워크를 사용하여 분산 네트워크(arg. Swarm service)를 구성할 수 있다.\nnone Networking none : 모든 네트워킹 드라이버, 그 어떠한 인터페이스도 없는 설정이다. 보통 커스텀 네트워크 드라이버를 구성할 경우 사용한다.\nmacvlan, ipvlan Networking 말그대로 가상 mac주소를 할당하여 물리적 호스트처럼 보이도록 설정하거나, L2,L3 모드가 필요할 때 사용한다. macvlan은 브릿지가 없는 대신 서브 인터페이스라 하여 부모 인터페이스 (eth0)에서 여러 하위 인터페이스를 만들어서 다량의 MAC주소를 부여한다. 이 하위 인터페이스들이 각 컨테이너에 연결되면서 vlan을 구축하는 방식이다.\nPod Networking Container Network에서 설명했듯이, 각각의 컨테이너는 독립적인 namesapce를 통해 격리되어진다.\n여기서 k8s의 Pods의 개념이 들어가면 같은 pod의 컨테이너들은 Network namespace를 공유한다.(컨테이너가 N개여도 veth는 1개) 그렇기에 동일한 IP를 사용한다.\n따라서 lookback 인터페이스를 통해 localhost+port 통신이 가능하다.\n이 Pod 내 컨테이너들의 Namespace를 공유해주는게 바로 pause 컨테이너이다.\nDocker Test GCP 환경에서 docker를 사용하여 이미지를 빌드하고 실행해봅시다.\nDocker 컨테이너 빌드, 실행과 Docker Hub 및 Google Container Registry에서 Docker 이미지 가져오기\n그리고 Dockerfile을 통해 이미지를 생성하는 법에 대해 간단하게 확인해봤습니다.\nHello World GCP에서 제공하는 Cloud shell을 열어 Hello world 컨테이너를 실행합니다.\ndocker run hello-world \u0026lt;--명령어 결과--\u0026gt; Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world b8dfde127a29: Pull complete Digest: sha256:9f6ad537c5132bcce57f7a0a20e317228d382c3cd61edae14650eec68b2b345c Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. 이 컨테이너는 shell에 \u0026ldquo;Hello from Docker!\u0026ldquo;라는 메시지를 반환합니다. 결과는 간단하지만 결과가 나오기 전에 이미지를 불러오는 과정을 확인해봅시다.\n로컬이미지에 Hello world이미지가 없기에 docker deamon은 docker hub라는 public registry에서 해당 이미지를 pull하여 컨테이너를 생성하고 실행하는 과정을 통해 위 메세지를 반환합니다.\ndocker hub에서 가져온 이미지를 확인해봅시다.\ndocker images \u0026lt;--명령어 결과--\u0026gt; REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest d1165f221234 3 months ago 13.3kB 여기서 알 수 있는 사실은 로컬에 이미지를 가지고 있지 않아도 docker deamon은 알아서 docker hub라는 public registry에서 이미지를 검색한다는 점입니다.\n이미지를 로컬로 Pull하였기에 두번쨰 실행부터는 바로 로컬이미지를 통해 컨테이너를 생성, 실행할 수 있는 것 입니다. 위 이미지는 echo \u0026ldquo;Hello from Docker!\u0026ldquo;를 실행하고 사라졌네요 마치 k8s의 jobs같습니다. 실제로 Docker ps -a 를 통해 컨테이너를 확인해보면 컨테이너가 종료되었음을 알 수 있습니다.\ndocker ps -a \u0026lt;--명령어 결과--\u0026gt; CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d36437eeb64a hello-world \u0026quot;/hello\u0026quot; About a minute ago Exited (0) About a minute ago sweet_pare 359b95d41706 hello-world \u0026quot;/hello\u0026quot; 2 minutes ago Exited (0) 2 minutes ago happy_ritchie docker run을 시작할때 옵션으로 \u0026ndash;name을 주면 뒤에 무작위로 붙는 Names 라벨을 설정해줄 수 도 있습니다.\nDockerFile build / run Test Dockerfile을 통해 직접 이미지를 빌드할 수 있습니다. 간단하게 CentOS에 Httpd를 띄우는 Dockerfile을 작성합니다.\ncat \u0026gt; Dockerfile \u0026lt;\u0026lt;EOF # CentOS7를 사용합니다. FROM centos:7 # 컨테이너에서 http 패키지를 설치해줍니다. RUN yum -y install httpd # 현재 디렉토리의 내용을 컨테이너 내부로 복사합니다. ADD /write-http.sh /write-http.sh # 컨테이너에서 write-http.sh를 실행할 수있도록 권한을 변경합니다. RUN chmod 755 /write-http.sh # 서비스를 위해 컨테이너의 포트 80을 외부에 공개합니다. EXPOSE 80 # 컨테이너가 시작될 때 write-http.sh 스크립트를 실행합니다. ENTRYPOINT [\u0026quot;sh\u0026quot;,\u0026quot;/etc/write-http.sh\u0026quot;] EOF # write-http.sh 내용 #!/bin/sh /usr/sbin/httpd -D FOREGROUND 이미지를 빌드하여 컨테이너에 띄워보면 아래와 같이 컨테이너가 생성됨을 알 수 있다.\ndocker build -t dominic-web:0.1 . \u0026lt;--명령어 결과--\u0026gt; Sending build context to Docker daemon 3.072kB Step 1/6 : FROM centos:7.5.1804 ---\u0026gt; cf49811e3cdb Step 2/6 : RUN yum -y install httpd ---\u0026gt; Using cache ---\u0026gt; b04936c42e77 Step 3/6 : ADD /write-http.sh /write-http.sh ---\u0026gt; 79d1a552ea2a Step 4/6 : RUN chmod 755 /write-http.sh ---\u0026gt; Running in 9041f099a392 Removing intermediate container 9041f099a392 ---\u0026gt; 96ce83e42fce Step 5/6 : EXPOSE 80 ---\u0026gt; Running in eb46efbe7e84 Removing intermediate container eb46efbe7e84 ---\u0026gt; b39def1a021e Step 6/6 : ENTRYPOINT [\u0026quot;sh\u0026quot;,\u0026quot;/etc/write-http.sh\u0026quot;] ---\u0026gt; Running in 7e258ee5d665 Removing intermediate container 7e258ee5d665 ---\u0026gt; d3924f695483 Successfully built d3924f695483 Successfully tagged dominic-web:0.1 docker images \u0026lt;--명령어 결과--\u0026gt; REPOSITORY TAG IMAGE ID CREATED SIZE dominic-web 0.1 d3924f695483 40 seconds ago 353MB 이후 docker run command를 통해 이미지를 컨테이너에 실행시키면 된다.\ndocker run -d -p 80:80 dominic-web:0.1 -d 옵션을 안주면 Foreground에서 동작하기에 쉘을 움직을 수가 없으니, -d 옵션으로 도커 컨테이너가 background에서 동작될 수 있도록 합시다!\n만약 다른 버전의 이미지를 생성하고 싶다면 간단합니다. 그냥 빌드할때, 태그를 달리해주면 된다.\ndocker build -t dominic-web:0.2 . 이후 빌드를하면 기존에 캐시되어있던 레이어는 넘어가고 변경사항이 생긴 레이어에서 수정이 발생함을 알 수 있을 것입니다.\n결과 ! curl로 확인해보니, httpd default page가 쫙~~나오네요. 다음엔 index.html을 좀 추가해야될듯 ㅎㅎ;\n간단하게 docker 테스트 진행해봤습니다.\n","date":"June 19, 2021","hero":"/posts/kubernetes/k8snetworking/images/CKA_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/kubernetes/k8snetworking/","summary":"\u003cp\u003e컨테이너 Network부터 Pod Network까지 기록해봤습니다.\u003c/p\u003e","tags":null,"title":"k8s(Networking)"},{"categories":null,"contents":"시작합시다.😎 도며든다\u0026hellip;도며든다\u0026hellip;\n안녕하세요, Dominic입니다.\n여유가 생길때마다 무엇이든, 어떤 내용이든 기록하고자 합니다.\n커다란 메모장이라고 생각해주세요. 100% 메모장\n방문하신 여러분들에게 조금이나마 도움이 되는 글이 되었기를 소망해봅니다. (●'◡'●)\n\u0026hellip;Written by Dominic (2021)\n LinkedIn | AWSKRUG | 2021-목표\n","date":"June 18, 2021","hero":"/posts/about_dominic/hero.svg","permalink":"https://hugo-toha.github.io/posts/about_dominic/","summary":"\u003cp\u003e시작합시다.😎 도며든다\u0026hellip;도며든다\u0026hellip;\u003c/p\u003e","tags":null,"title":"About_dominic😎"},{"categories":null,"contents":"기본적인 kubernetes의 구성요소들에 대해 간단하게 기록했습니다.\nk8s Architecture 환경 : Amazon Linux 2 (t2 패밀리) k8s version : v1.21 설치 방법 : Kubeadm | CNI : Flannel  Master node와 worker Node로 구성됨  master node 구성 : API server, Scheduler, Controller, etcd (클러스터의 상태, 컨테이너설정, 네트워킹 구성 등 관리) -각 control plane component들은 뒤에서 상세히 다룰 에정. Worker node 구성 : kubelet, kube-proxy   k8s 동작 방식  API server를 통해 API를 노출한다. Kubectl이라는 로컬 클라이언트를 사용하여 API와 통신한다. Scheduler는 이러한 API들을 적절한 노드로 할당해주는 스케줄링 작업을 담당한다. 각 worker node들에서 kubelet은 컨테이너 실행 요청을 수신하고 필요한 리소스들을 관리한다. 각 worker node들에서 kube-proxy는 컨테이너의 네트워크를 담당한다.    기본적으로 각 pod에서는 클러스터의 모든 노드에서 실행되는 다른 모든 pod에 대한 액세스가 제한되지 않지만 개발자가 pod 간 액세스를 제한할 수 있다.\n또한 노드 풀이 업그레이드될 때, pod의 선언적 구성을 변경하거나 컨테이너의 이미지를 변경할 때 또는 노드가 사용 불가능하게 될 때 Control Plane에서는 스케쥴러에 의해 파드의 구성이 변경된다.\n따라서 pod의 개념자체가 영구적인 지속이 아니기에 언제든지 pod는 재생성 될 수 있다. 그렇기에 Pod의 IP를 의존하면 안된다. k8s의 서비스를 사용해서 안정적인 엔드포인트를 통해 운영해야된다.\nService 서비스는 라벨을 사용하여 어떤 포드에서 작동할지 결정한다. 포드에 라벨이 정확히 지정되어 있다면 서비스가 이를 자동으로 감지하고 노출시킨다.\n서비스가 제공하는 포드 집합에 대한 액세스 수준은 서비스 유형에 따라 다르며 3가지 유형이 있다.\n ClusterIP(내부) : 기본 유형이며 이 서비스는 클러스터 안에서만 볼 수 있다. NodePort : 클러스터의 각 노드에 외부에서 액세스 가능한 IP 주소를 제공한다. LoadBalancer : 클라우드 제공업체로부터 부하 분산기를 추가하며 서비스에서 유입되는 트래픽을 내부에 있는 노드로 전달한다.  k8s Component  Control Plane   worker node와 클러스터 내 파드를 관리  kube-scheduler : 정의된 replicaset의 요구조건 충족, 노드가 배정되지않은 파드의 배치 등등 worker node에 있는 Pod를 스케줄링하는 역할 kube-apiserver : Control Plane의 FE / API를 노출하는 역할 / k8s Cluster와 상호작용을 위한 api 서버 etcd : 클러스터의 상태를 저장하여 일관성을 유지한다. (Data store) / Master Cluster에서 k8s object 저장소로 사용 kube-controller-manager :Deployments나 replcation Controller등 관리  node-controller replication-controller endpoint-controller service-account\u0026amp;token-controller   cloud-controller-manager :Public Cloud Provider 연동 관리  node-controller route-contoller service-contoller      Node Component   worker node 내 pod들을 유지  Kubelet : k8s를 통해 생성된 Pod 내 컨테이너의 동작에 관여한다. 가령 정확한 스펙에 따라 동작하는지 등.. kube-proxy : 각 worker node에서 실행되는 proxy로 서비스의 개념을 구현한다. (Inbound,Outbound) container runtime : docker, cri-o 등등..    CNI (Contanier Network Interface)   Pod가 생성되고 삭제될 때, 호출되는 API의 규격과 인터페이스를 정의해준다. (그니까.. Pod Network를 구축하는 플러그인들) CNI마다 기본적으로 차지하는 리소스가 있기에 목적에 맞게..사용해야한다. 이미 훌륭하신분들이 테스트한 자료가 구글에\u0026hellip;!! 결론적으로 성능이 잘 나와야하고, 부가기능(ACL)을 지원하는 등 목적에 맞게 선택해야 된다. 영원한 선택의 늪  k8s Object   Pod : Worker Node 내 컨테이너들의 집합 (비영구적이다.)\n 하나의 pod에는 한개 이상의 서비스로 지정될 수 있다. 각각의 pod에는 veth가 할당됨 (파드내 컨테이너들은 veth, PID, 를 공유 [누가?! pause 컨테이너])    Service : Label로 묶어서 Endpoint를 노출시킴\n  configmap : pod에 담겨진 컨테이너에서 사용되는 구성 값\n  secret : 특수 볼륨에 연결되어 컨테이너에서 사용가능 (mysql 패스워드 같은것들을 저장해두고 환경변수로 가져오는 방식으로 사용)\n  deployment Controller : pod 배포 및 관리에 사용하는 컨트롤러 : ReplicaSet을 자동으로 생성 : pod에 대한 Rolling 업데이트를 관리 (versioning)\n ReplicaSet : 사용자가 template에 명시해둔 Pod의 갯수를 유지한다. StatefulSet : Pod별 고정된 identity 할당 (name, network id 등) DamonSet : 모든 node에 배포되어 실행 (Node Selector로 정의하는 경우 일부 node에서 실행시키는 등 제어 가능, ) : 특정 노드 또는 모든 노드에 항상 실행되어 있어야 하는 특정 파드들을 관리한다. 가령 로그수집용도의 파드들..! Jobs : batch성 작업들, 특성 task 실행을 위해 하나 이상의 pod를 생성해서 task를 실행한 후 완료되면 Pod를 제거한다. (순차, 동시실행 지원, 다만 Lifecycle설정필요)    Volume : Pod에 연결되어 디렉토리 형태로 데이터를 저장 (파드 간 컨테이너끼리 공유하며 Pod와 동일한 수명주기를 가짐)\n  PersistentVolume : k8s에서 관리하는 저장소, Pod와 독립적은 수명주기를 가짐(사용자가 PVC를 정의하고 생성하면 대응하는 PV가 생기는 형식)\n  알아두면 좋을 3rt party tool  Helm : 사전 정의된 k8s 리소스에 대한 패키지 Kompose : docker compose를 K8s object로 변환 ","date":"June 17, 2021","hero":"/posts/kubernetes/k8scomponent/images/CKA_thumnail.jpg","permalink":"https://hugo-toha.github.io/posts/kubernetes/k8scomponent/","summary":"\u003cp\u003e기본적인 kubernetes의 구성요소들에 대해 간단하게 기록했습니다.\u003c/p\u003e","tags":null,"title":"k8s(component)"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ``` \u0026hellip; \u0026ldquo;contents\u0026rdquo;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026ldquo;tags\u0026rdquo;:{{ .Params.tags | jsonify }}{{end}}, \u0026ldquo;categories\u0026rdquo; : {{ .Params.categories | jsonify }}, \u0026hellip; ```\nEdit fuse.js options to Search static/js/search.js ``` keys: [ \u0026ldquo;title\u0026rdquo;, \u0026ldquo;contents\u0026rdquo;, \u0026ldquo;tags\u0026rdquo;, \u0026ldquo;categories\u0026rdquo; ] ```\n","date":"January 1, 0001","hero":"/images/default-hero.jpg","permalink":"https://hugo-toha.github.io/search/","summary":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ``` [outputs] home = [\u0026ldquo;HTML\u0026rdquo;, \u0026ldquo;JSON\u0026rdquo;] ```","tags":null,"title":"Search Results"}]